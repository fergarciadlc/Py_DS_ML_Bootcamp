{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Classification (continue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../DATA/cancer_classification.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Feature Engineering, Train Test Split, Scale data\n",
    "\n",
    "**TARGET**: benign_0__mal_1\n",
    "\n",
    "**NOTE**: Remeber to add .values to have them in numpy form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('benign_0__mal_1', axis=1).values\n",
    "y = df['benign_0__mal_1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale Data **AFTER** the split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 30)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "30 Neurons on first layer (input layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(30,'relu')) # 1st layer (INPUT)\n",
    "model.add(Dense(15,'relu')) # 2nd layer\n",
    "\n",
    "#Last layer, one neuron and SIGMOID (BINARY CLASSIFICATION)\n",
    "model.add(Dense(1,'sigmoid'))\n",
    "\n",
    "# For a binary classification problem\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model, first too many epochs in order to **overfit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 426 samples, validate on 143 samples\n",
      "Epoch 1/600\n",
      "426/426 [==============================] - 3s 6ms/sample - loss: 0.6828 - val_loss: 0.6600\n",
      "Epoch 2/600\n",
      "426/426 [==============================] - 0s 462us/sample - loss: 0.6435 - val_loss: 0.6227\n",
      "Epoch 3/600\n",
      "426/426 [==============================] - 0s 478us/sample - loss: 0.6009 - val_loss: 0.5812\n",
      "Epoch 4/600\n",
      "426/426 [==============================] - 0s 456us/sample - loss: 0.5574 - val_loss: 0.5325\n",
      "Epoch 5/600\n",
      "426/426 [==============================] - 0s 353us/sample - loss: 0.5094 - val_loss: 0.4823\n",
      "Epoch 6/600\n",
      "426/426 [==============================] - 0s 350us/sample - loss: 0.4599 - val_loss: 0.4307\n",
      "Epoch 7/600\n",
      "426/426 [==============================] - 0s 356us/sample - loss: 0.4120 - val_loss: 0.3821\n",
      "Epoch 8/600\n",
      "426/426 [==============================] - 0s 350us/sample - loss: 0.3678 - val_loss: 0.3387\n",
      "Epoch 9/600\n",
      "426/426 [==============================] - 0s 392us/sample - loss: 0.3294 - val_loss: 0.3003\n",
      "Epoch 10/600\n",
      "426/426 [==============================] - 0s 331us/sample - loss: 0.2996 - val_loss: 0.2752\n",
      "Epoch 11/600\n",
      "426/426 [==============================] - 0s 375us/sample - loss: 0.2809 - val_loss: 0.2491\n",
      "Epoch 12/600\n",
      "426/426 [==============================] - 0s 335us/sample - loss: 0.2607 - val_loss: 0.2310\n",
      "Epoch 13/600\n",
      "426/426 [==============================] - 0s 344us/sample - loss: 0.2381 - val_loss: 0.2181\n",
      "Epoch 14/600\n",
      "426/426 [==============================] - 0s 353us/sample - loss: 0.2246 - val_loss: 0.2033\n",
      "Epoch 15/600\n",
      "426/426 [==============================] - 0s 352us/sample - loss: 0.2130 - val_loss: 0.1924\n",
      "Epoch 16/600\n",
      "426/426 [==============================] - 0s 352us/sample - loss: 0.1996 - val_loss: 0.1818\n",
      "Epoch 17/600\n",
      "426/426 [==============================] - 0s 344us/sample - loss: 0.1891 - val_loss: 0.1745\n",
      "Epoch 18/600\n",
      "426/426 [==============================] - 0s 350us/sample - loss: 0.1783 - val_loss: 0.1651\n",
      "Epoch 19/600\n",
      "426/426 [==============================] - 0s 367us/sample - loss: 0.1717 - val_loss: 0.1623\n",
      "Epoch 20/600\n",
      "426/426 [==============================] - 0s 322us/sample - loss: 0.1637 - val_loss: 0.1525\n",
      "Epoch 21/600\n",
      "426/426 [==============================] - 0s 402us/sample - loss: 0.1541 - val_loss: 0.1472\n",
      "Epoch 22/600\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.152 - 0s 400us/sample - loss: 0.1462 - val_loss: 0.1443\n",
      "Epoch 23/600\n",
      "426/426 [==============================] - 0s 350us/sample - loss: 0.1396 - val_loss: 0.1375\n",
      "Epoch 24/600\n",
      "426/426 [==============================] - 0s 381us/sample - loss: 0.1345 - val_loss: 0.1337\n",
      "Epoch 25/600\n",
      "426/426 [==============================] - 0s 374us/sample - loss: 0.1266 - val_loss: 0.1324\n",
      "Epoch 26/600\n",
      "426/426 [==============================] - 0s 360us/sample - loss: 0.1226 - val_loss: 0.1266\n",
      "Epoch 27/600\n",
      "426/426 [==============================] - 0s 348us/sample - loss: 0.1201 - val_loss: 0.1257\n",
      "Epoch 28/600\n",
      "426/426 [==============================] - 0s 360us/sample - loss: 0.1125 - val_loss: 0.1211\n",
      "Epoch 29/600\n",
      "426/426 [==============================] - 0s 357us/sample - loss: 0.1070 - val_loss: 0.1216\n",
      "Epoch 30/600\n",
      "426/426 [==============================] - 0s 363us/sample - loss: 0.1032 - val_loss: 0.1176\n",
      "Epoch 31/600\n",
      "426/426 [==============================] - 0s 345us/sample - loss: 0.0976 - val_loss: 0.1180\n",
      "Epoch 32/600\n",
      "426/426 [==============================] - 0s 301us/sample - loss: 0.0949 - val_loss: 0.1138\n",
      "Epoch 33/600\n",
      "426/426 [==============================] - 0s 316us/sample - loss: 0.0915 - val_loss: 0.1121\n",
      "Epoch 34/600\n",
      "426/426 [==============================] - 0s 322us/sample - loss: 0.0881 - val_loss: 0.1123\n",
      "Epoch 35/600\n",
      "426/426 [==============================] - 0s 331us/sample - loss: 0.0858 - val_loss: 0.1117\n",
      "Epoch 36/600\n",
      "426/426 [==============================] - 0s 300us/sample - loss: 0.0825 - val_loss: 0.1079\n",
      "Epoch 37/600\n",
      "426/426 [==============================] - 0s 317us/sample - loss: 0.0803 - val_loss: 0.1122\n",
      "Epoch 38/600\n",
      "426/426 [==============================] - 0s 316us/sample - loss: 0.0789 - val_loss: 0.1073\n",
      "Epoch 39/600\n",
      "426/426 [==============================] - 0s 314us/sample - loss: 0.0771 - val_loss: 0.1071\n",
      "Epoch 40/600\n",
      "426/426 [==============================] - 0s 327us/sample - loss: 0.0791 - val_loss: 0.1107\n",
      "Epoch 41/600\n",
      "426/426 [==============================] - 0s 317us/sample - loss: 0.0736 - val_loss: 0.1053\n",
      "Epoch 42/600\n",
      "426/426 [==============================] - 0s 319us/sample - loss: 0.0716 - val_loss: 0.1061\n",
      "Epoch 43/600\n",
      "426/426 [==============================] - 0s 309us/sample - loss: 0.0713 - val_loss: 0.1037\n",
      "Epoch 44/600\n",
      "426/426 [==============================] - 0s 311us/sample - loss: 0.0709 - val_loss: 0.1063\n",
      "Epoch 45/600\n",
      "426/426 [==============================] - 0s 329us/sample - loss: 0.0712 - val_loss: 0.1038\n",
      "Epoch 46/600\n",
      "426/426 [==============================] - 0s 319us/sample - loss: 0.0688 - val_loss: 0.1051\n",
      "Epoch 47/600\n",
      "426/426 [==============================] - 0s 308us/sample - loss: 0.0686 - val_loss: 0.1098\n",
      "Epoch 48/600\n",
      "426/426 [==============================] - 0s 312us/sample - loss: 0.0648 - val_loss: 0.1013\n",
      "Epoch 49/600\n",
      "426/426 [==============================] - 0s 319us/sample - loss: 0.0667 - val_loss: 0.1060\n",
      "Epoch 50/600\n",
      "426/426 [==============================] - 0s 310us/sample - loss: 0.0631 - val_loss: 0.1031\n",
      "Epoch 51/600\n",
      "426/426 [==============================] - 0s 315us/sample - loss: 0.0624 - val_loss: 0.1085\n",
      "Epoch 52/600\n",
      "426/426 [==============================] - 0s 312us/sample - loss: 0.0613 - val_loss: 0.1011\n",
      "Epoch 53/600\n",
      "426/426 [==============================] - 0s 305us/sample - loss: 0.0610 - val_loss: 0.1038\n",
      "Epoch 54/600\n",
      "426/426 [==============================] - 0s 309us/sample - loss: 0.0599 - val_loss: 0.1017\n",
      "Epoch 55/600\n",
      "426/426 [==============================] - 0s 315us/sample - loss: 0.0606 - val_loss: 0.1030\n",
      "Epoch 56/600\n",
      "426/426 [==============================] - 0s 315us/sample - loss: 0.0600 - val_loss: 0.1051\n",
      "Epoch 57/600\n",
      "426/426 [==============================] - 0s 296us/sample - loss: 0.0589 - val_loss: 0.1062\n",
      "Epoch 58/600\n",
      "426/426 [==============================] - 0s 286us/sample - loss: 0.0584 - val_loss: 0.1035\n",
      "Epoch 59/600\n",
      "426/426 [==============================] - 0s 289us/sample - loss: 0.0572 - val_loss: 0.1069\n",
      "Epoch 60/600\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.050 - 0s 303us/sample - loss: 0.0571 - val_loss: 0.1031\n",
      "Epoch 61/600\n",
      "426/426 [==============================] - 0s 286us/sample - loss: 0.0574 - val_loss: 0.1055\n",
      "Epoch 62/600\n",
      "426/426 [==============================] - 0s 282us/sample - loss: 0.0558 - val_loss: 0.1043\n",
      "Epoch 63/600\n",
      "426/426 [==============================] - 0s 291us/sample - loss: 0.0568 - val_loss: 0.1047\n",
      "Epoch 64/600\n",
      "426/426 [==============================] - 0s 291us/sample - loss: 0.0555 - val_loss: 0.1004\n",
      "Epoch 65/600\n",
      "426/426 [==============================] - 0s 333us/sample - loss: 0.0563 - val_loss: 0.1112\n",
      "Epoch 66/600\n",
      "426/426 [==============================] - 0s 294us/sample - loss: 0.0588 - val_loss: 0.1101\n",
      "Epoch 67/600\n",
      "426/426 [==============================] - 0s 291us/sample - loss: 0.0542 - val_loss: 0.1007\n",
      "Epoch 68/600\n",
      "426/426 [==============================] - 0s 289us/sample - loss: 0.0551 - val_loss: 0.1077\n",
      "Epoch 69/600\n",
      "426/426 [==============================] - 0s 279us/sample - loss: 0.0546 - val_loss: 0.1042\n",
      "Epoch 70/600\n",
      "426/426 [==============================] - 0s 261us/sample - loss: 0.0540 - val_loss: 0.1052\n",
      "Epoch 71/600\n",
      "426/426 [==============================] - 0s 261us/sample - loss: 0.0532 - val_loss: 0.1051\n",
      "Epoch 72/600\n",
      "426/426 [==============================] - 0s 268us/sample - loss: 0.0532 - val_loss: 0.1061\n",
      "Epoch 73/600\n",
      "426/426 [==============================] - 0s 277us/sample - loss: 0.0531 - val_loss: 0.1042\n",
      "Epoch 74/600\n",
      "426/426 [==============================] - 0s 266us/sample - loss: 0.0527 - val_loss: 0.1044\n",
      "Epoch 75/600\n",
      "426/426 [==============================] - 0s 265us/sample - loss: 0.0529 - val_loss: 0.1067\n",
      "Epoch 76/600\n",
      "426/426 [==============================] - 0s 251us/sample - loss: 0.0540 - val_loss: 0.1046\n",
      "Epoch 77/600\n",
      "426/426 [==============================] - 0s 256us/sample - loss: 0.0596 - val_loss: 0.1041\n",
      "Epoch 78/600\n",
      "426/426 [==============================] - 0s 249us/sample - loss: 0.0530 - val_loss: 0.1003\n",
      "Epoch 79/600\n",
      "426/426 [==============================] - 0s 251us/sample - loss: 0.0516 - val_loss: 0.1129\n",
      "Epoch 80/600\n",
      "426/426 [==============================] - 0s 261us/sample - loss: 0.0517 - val_loss: 0.1026\n",
      "Epoch 81/600\n",
      "426/426 [==============================] - 0s 279us/sample - loss: 0.0508 - val_loss: 0.1050\n",
      "Epoch 82/600\n",
      "426/426 [==============================] - 0s 265us/sample - loss: 0.0502 - val_loss: 0.1096\n",
      "Epoch 83/600\n",
      "426/426 [==============================] - 0s 258us/sample - loss: 0.0501 - val_loss: 0.1046\n",
      "Epoch 84/600\n",
      "426/426 [==============================] - 0s 261us/sample - loss: 0.0517 - val_loss: 0.1072\n",
      "Epoch 85/600\n",
      "426/426 [==============================] - 0s 263us/sample - loss: 0.0509 - val_loss: 0.1032\n",
      "Epoch 86/600\n",
      "426/426 [==============================] - 0s 253us/sample - loss: 0.0497 - val_loss: 0.1014\n",
      "Epoch 87/600\n",
      "426/426 [==============================] - 0s 251us/sample - loss: 0.0497 - val_loss: 0.1115\n",
      "Epoch 88/600\n",
      "426/426 [==============================] - 0s 259us/sample - loss: 0.0497 - val_loss: 0.1110\n",
      "Epoch 89/600\n",
      "426/426 [==============================] - 0s 308us/sample - loss: 0.0524 - val_loss: 0.1053\n",
      "Epoch 90/600\n",
      "426/426 [==============================] - 0s 225us/sample - loss: 0.0492 - val_loss: 0.1101\n",
      "Epoch 91/600\n",
      "426/426 [==============================] - 0s 225us/sample - loss: 0.0501 - val_loss: 0.1078\n",
      "Epoch 92/600\n",
      "426/426 [==============================] - 0s 265us/sample - loss: 0.0491 - val_loss: 0.1082\n",
      "Epoch 93/600\n",
      "426/426 [==============================] - 0s 225us/sample - loss: 0.0524 - val_loss: 0.1136\n",
      "Epoch 94/600\n",
      "426/426 [==============================] - 0s 232us/sample - loss: 0.0544 - val_loss: 0.1102\n",
      "Epoch 95/600\n",
      "426/426 [==============================] - 0s 218us/sample - loss: 0.0571 - val_loss: 0.1039\n",
      "Epoch 96/600\n",
      "426/426 [==============================] - 0s 231us/sample - loss: 0.0511 - val_loss: 0.1109\n",
      "Epoch 97/600\n",
      "426/426 [==============================] - 0s 222us/sample - loss: 0.0485 - val_loss: 0.1079\n",
      "Epoch 98/600\n",
      "426/426 [==============================] - 0s 251us/sample - loss: 0.0526 - val_loss: 0.1106\n",
      "Epoch 99/600\n",
      "426/426 [==============================] - 0s 242us/sample - loss: 0.0492 - val_loss: 0.1062\n",
      "Epoch 100/600\n",
      "426/426 [==============================] - 0s 235us/sample - loss: 0.0552 - val_loss: 0.1225\n",
      "Epoch 101/600\n",
      "426/426 [==============================] - 0s 211us/sample - loss: 0.0485 - val_loss: 0.1072\n",
      "Epoch 102/600\n",
      "426/426 [==============================] - 0s 223us/sample - loss: 0.0474 - val_loss: 0.1127\n",
      "Epoch 103/600\n",
      "426/426 [==============================] - 0s 232us/sample - loss: 0.0489 - val_loss: 0.1118\n",
      "Epoch 104/600\n",
      "426/426 [==============================] - 0s 216us/sample - loss: 0.0483 - val_loss: 0.1055\n",
      "Epoch 105/600\n",
      "426/426 [==============================] - 0s 225us/sample - loss: 0.0475 - val_loss: 0.1099\n",
      "Epoch 106/600\n",
      "426/426 [==============================] - 0s 216us/sample - loss: 0.0470 - val_loss: 0.1102\n",
      "Epoch 107/600\n",
      "426/426 [==============================] - 0s 221us/sample - loss: 0.0491 - val_loss: 0.1048\n",
      "Epoch 108/600\n",
      "426/426 [==============================] - 0s 209us/sample - loss: 0.0472 - val_loss: 0.1114\n",
      "Epoch 109/600\n",
      "426/426 [==============================] - 0s 232us/sample - loss: 0.0460 - val_loss: 0.1076\n",
      "Epoch 110/600\n",
      "426/426 [==============================] - 0s 221us/sample - loss: 0.0463 - val_loss: 0.1175\n",
      "Epoch 111/600\n",
      "426/426 [==============================] - 0s 207us/sample - loss: 0.0467 - val_loss: 0.1053\n",
      "Epoch 112/600\n",
      "426/426 [==============================] - 0s 200us/sample - loss: 0.0464 - val_loss: 0.1096\n",
      "Epoch 113/600\n",
      "426/426 [==============================] - 0s 234us/sample - loss: 0.0476 - val_loss: 0.1060\n",
      "Epoch 114/600\n",
      "426/426 [==============================] - 0s 228us/sample - loss: 0.0472 - val_loss: 0.1162\n",
      "Epoch 115/600\n",
      "426/426 [==============================] - 0s 225us/sample - loss: 0.0462 - val_loss: 0.1135\n",
      "Epoch 116/600\n",
      "426/426 [==============================] - 0s 228us/sample - loss: 0.0450 - val_loss: 0.1096\n",
      "Epoch 117/600\n",
      "426/426 [==============================] - 0s 230us/sample - loss: 0.0468 - val_loss: 0.1091\n",
      "Epoch 118/600\n",
      "426/426 [==============================] - 0s 235us/sample - loss: 0.0460 - val_loss: 0.1124\n",
      "Epoch 119/600\n",
      "426/426 [==============================] - 0s 219us/sample - loss: 0.0449 - val_loss: 0.1119\n",
      "Epoch 120/600\n",
      "426/426 [==============================] - 0s 232us/sample - loss: 0.0451 - val_loss: 0.1157\n",
      "Epoch 121/600\n",
      "426/426 [==============================] - 0s 209us/sample - loss: 0.0452 - val_loss: 0.1115\n",
      "Epoch 122/600\n",
      "426/426 [==============================] - 0s 211us/sample - loss: 0.0450 - val_loss: 0.1161\n",
      "Epoch 123/600\n",
      "426/426 [==============================] - 0s 216us/sample - loss: 0.0476 - val_loss: 0.1059\n",
      "Epoch 124/600\n",
      "426/426 [==============================] - 0s 223us/sample - loss: 0.0461 - val_loss: 0.1128\n",
      "Epoch 125/600\n",
      "426/426 [==============================] - 0s 209us/sample - loss: 0.0445 - val_loss: 0.1148\n",
      "Epoch 126/600\n",
      "426/426 [==============================] - 0s 230us/sample - loss: 0.0449 - val_loss: 0.1163\n",
      "Epoch 127/600\n",
      "426/426 [==============================] - 0s 230us/sample - loss: 0.0463 - val_loss: 0.1086\n",
      "Epoch 128/600\n",
      "426/426 [==============================] - 0s 214us/sample - loss: 0.0508 - val_loss: 0.1186\n",
      "Epoch 129/600\n",
      "426/426 [==============================] - 0s 228us/sample - loss: 0.0429 - val_loss: 0.1087\n",
      "Epoch 130/600\n",
      "426/426 [==============================] - 0s 218us/sample - loss: 0.0445 - val_loss: 0.1167\n",
      "Epoch 131/600\n",
      "426/426 [==============================] - 0s 224us/sample - loss: 0.0446 - val_loss: 0.1100\n",
      "Epoch 132/600\n",
      "426/426 [==============================] - 0s 237us/sample - loss: 0.0439 - val_loss: 0.1161\n",
      "Epoch 133/600\n",
      "426/426 [==============================] - 0s 209us/sample - loss: 0.0435 - val_loss: 0.1146\n",
      "Epoch 134/600\n",
      "426/426 [==============================] - 0s 204us/sample - loss: 0.0466 - val_loss: 0.1183\n",
      "Epoch 135/600\n",
      "426/426 [==============================] - 0s 191us/sample - loss: 0.0425 - val_loss: 0.1123\n",
      "Epoch 136/600\n",
      "426/426 [==============================] - 0s 262us/sample - loss: 0.0457 - val_loss: 0.1078\n",
      "Epoch 137/600\n",
      "426/426 [==============================] - 0s 236us/sample - loss: 0.0444 - val_loss: 0.1138\n",
      "Epoch 138/600\n",
      "426/426 [==============================] - 0s 211us/sample - loss: 0.0441 - val_loss: 0.1222\n",
      "Epoch 139/600\n",
      "426/426 [==============================] - 0s 209us/sample - loss: 0.0486 - val_loss: 0.1175\n",
      "Epoch 140/600\n",
      "426/426 [==============================] - 0s 237us/sample - loss: 0.0423 - val_loss: 0.1142\n",
      "Epoch 141/600\n",
      "426/426 [==============================] - 0s 226us/sample - loss: 0.0425 - val_loss: 0.1192\n",
      "Epoch 142/600\n",
      "426/426 [==============================] - 0s 204us/sample - loss: 0.0439 - val_loss: 0.1175\n",
      "Epoch 143/600\n",
      "426/426 [==============================] - 0s 237us/sample - loss: 0.0420 - val_loss: 0.1181\n",
      "Epoch 144/600\n",
      "426/426 [==============================] - 0s 211us/sample - loss: 0.0430 - val_loss: 0.1182\n",
      "Epoch 145/600\n",
      "426/426 [==============================] - 0s 236us/sample - loss: 0.0501 - val_loss: 0.1152\n",
      "Epoch 146/600\n",
      "426/426 [==============================] - 0s 197us/sample - loss: 0.0457 - val_loss: 0.1306\n",
      "Epoch 147/600\n",
      "426/426 [==============================] - 0s 223us/sample - loss: 0.0445 - val_loss: 0.1154\n",
      "Epoch 148/600\n",
      "426/426 [==============================] - 0s 207us/sample - loss: 0.0413 - val_loss: 0.1138\n",
      "Epoch 149/600\n",
      "426/426 [==============================] - 0s 214us/sample - loss: 0.0431 - val_loss: 0.1149\n",
      "Epoch 150/600\n",
      "426/426 [==============================] - 0s 221us/sample - loss: 0.0442 - val_loss: 0.1153\n",
      "Epoch 151/600\n",
      "426/426 [==============================] - 0s 221us/sample - loss: 0.0408 - val_loss: 0.1197\n",
      "Epoch 152/600\n",
      "426/426 [==============================] - 0s 214us/sample - loss: 0.0408 - val_loss: 0.1178\n",
      "Epoch 153/600\n",
      "426/426 [==============================] - 0s 235us/sample - loss: 0.0414 - val_loss: 0.1212\n",
      "Epoch 154/600\n",
      "426/426 [==============================] - 0s 244us/sample - loss: 0.0430 - val_loss: 0.1230\n",
      "Epoch 155/600\n",
      "426/426 [==============================] - 0s 225us/sample - loss: 0.0414 - val_loss: 0.1170\n",
      "Epoch 156/600\n",
      "426/426 [==============================] - 0s 232us/sample - loss: 0.0420 - val_loss: 0.1176\n",
      "Epoch 157/600\n",
      "426/426 [==============================] - 0s 225us/sample - loss: 0.0403 - val_loss: 0.1263\n",
      "Epoch 158/600\n",
      "426/426 [==============================] - 0s 235us/sample - loss: 0.0441 - val_loss: 0.1232\n",
      "Epoch 159/600\n",
      "426/426 [==============================] - 0s 223us/sample - loss: 0.0433 - val_loss: 0.1206\n",
      "Epoch 160/600\n",
      "426/426 [==============================] - 0s 230us/sample - loss: 0.0421 - val_loss: 0.1221\n",
      "Epoch 161/600\n",
      "426/426 [==============================] - 0s 225us/sample - loss: 0.0409 - val_loss: 0.1193\n",
      "Epoch 162/600\n",
      "426/426 [==============================] - 0s 234us/sample - loss: 0.0408 - val_loss: 0.1201\n",
      "Epoch 163/600\n",
      "426/426 [==============================] - 0s 225us/sample - loss: 0.0425 - val_loss: 0.1163\n",
      "Epoch 164/600\n",
      "426/426 [==============================] - 0s 223us/sample - loss: 0.0424 - val_loss: 0.1215\n",
      "Epoch 165/600\n",
      "426/426 [==============================] - 0s 286us/sample - loss: 0.0409 - val_loss: 0.1206\n",
      "Epoch 166/600\n",
      "426/426 [==============================] - 0s 231us/sample - loss: 0.0407 - val_loss: 0.1284\n",
      "Epoch 167/600\n",
      "426/426 [==============================] - 0s 258us/sample - loss: 0.0444 - val_loss: 0.1237\n",
      "Epoch 168/600\n",
      "426/426 [==============================] - 0s 218us/sample - loss: 0.0409 - val_loss: 0.1293\n",
      "Epoch 169/600\n",
      "426/426 [==============================] - 0s 235us/sample - loss: 0.0416 - val_loss: 0.1293\n",
      "Epoch 170/600\n",
      "426/426 [==============================] - 0s 223us/sample - loss: 0.0389 - val_loss: 0.1213\n",
      "Epoch 171/600\n",
      "426/426 [==============================] - 0s 230us/sample - loss: 0.0394 - val_loss: 0.1285\n",
      "Epoch 172/600\n",
      "426/426 [==============================] - 0s 226us/sample - loss: 0.0404 - val_loss: 0.1198\n",
      "Epoch 173/600\n",
      "426/426 [==============================] - 0s 221us/sample - loss: 0.0431 - val_loss: 0.1290\n",
      "Epoch 174/600\n",
      "426/426 [==============================] - 0s 223us/sample - loss: 0.0386 - val_loss: 0.1194\n",
      "Epoch 175/600\n",
      "426/426 [==============================] - 0s 207us/sample - loss: 0.0437 - val_loss: 0.1308\n",
      "Epoch 176/600\n",
      "426/426 [==============================] - 0s 200us/sample - loss: 0.0417 - val_loss: 0.1279\n",
      "Epoch 177/600\n",
      "426/426 [==============================] - 0s 204us/sample - loss: 0.0416 - val_loss: 0.1265\n",
      "Epoch 178/600\n",
      "426/426 [==============================] - 0s 209us/sample - loss: 0.0414 - val_loss: 0.1311\n",
      "Epoch 179/600\n",
      "426/426 [==============================] - 0s 214us/sample - loss: 0.0386 - val_loss: 0.1340\n",
      "Epoch 180/600\n",
      "426/426 [==============================] - 0s 214us/sample - loss: 0.0382 - val_loss: 0.1272\n",
      "Epoch 181/600\n",
      "426/426 [==============================] - 0s 237us/sample - loss: 0.0390 - val_loss: 0.1363\n",
      "Epoch 182/600\n",
      "426/426 [==============================] - 0s 225us/sample - loss: 0.0388 - val_loss: 0.1253\n",
      "Epoch 183/600\n",
      "426/426 [==============================] - 0s 218us/sample - loss: 0.0392 - val_loss: 0.1311\n",
      "Epoch 184/600\n",
      "426/426 [==============================] - 0s 200us/sample - loss: 0.0407 - val_loss: 0.1407\n",
      "Epoch 185/600\n",
      "426/426 [==============================] - 0s 200us/sample - loss: 0.0386 - val_loss: 0.1249\n",
      "Epoch 186/600\n",
      "426/426 [==============================] - 0s 199us/sample - loss: 0.0413 - val_loss: 0.1347\n",
      "Epoch 187/600\n",
      "426/426 [==============================] - 0s 207us/sample - loss: 0.0394 - val_loss: 0.1288\n",
      "Epoch 188/600\n",
      "426/426 [==============================] - 0s 207us/sample - loss: 0.0403 - val_loss: 0.1359\n",
      "Epoch 189/600\n",
      "426/426 [==============================] - 0s 218us/sample - loss: 0.0453 - val_loss: 0.1265\n",
      "Epoch 190/600\n",
      "426/426 [==============================] - 0s 237us/sample - loss: 0.0416 - val_loss: 0.1301\n",
      "Epoch 191/600\n",
      "426/426 [==============================] - 0s 209us/sample - loss: 0.0375 - val_loss: 0.1231\n",
      "Epoch 192/600\n",
      "426/426 [==============================] - 0s 214us/sample - loss: 0.0438 - val_loss: 0.1400\n",
      "Epoch 193/600\n",
      "426/426 [==============================] - 0s 211us/sample - loss: 0.0422 - val_loss: 0.1200\n",
      "Epoch 194/600\n",
      "426/426 [==============================] - 0s 224us/sample - loss: 0.0395 - val_loss: 0.1348\n",
      "Epoch 195/600\n",
      "426/426 [==============================] - 0s 208us/sample - loss: 0.0382 - val_loss: 0.1207\n",
      "Epoch 196/600\n",
      "426/426 [==============================] - 0s 207us/sample - loss: 0.0420 - val_loss: 0.1233\n",
      "Epoch 197/600\n",
      "426/426 [==============================] - 0s 228us/sample - loss: 0.0397 - val_loss: 0.1270\n",
      "Epoch 198/600\n",
      "426/426 [==============================] - 0s 203us/sample - loss: 0.0386 - val_loss: 0.1256\n",
      "Epoch 199/600\n",
      "426/426 [==============================] - 0s 261us/sample - loss: 0.0403 - val_loss: 0.1246\n",
      "Epoch 200/600\n",
      "426/426 [==============================] - 0s 254us/sample - loss: 0.0394 - val_loss: 0.1280\n",
      "Epoch 201/600\n",
      "426/426 [==============================] - 0s 271us/sample - loss: 0.0400 - val_loss: 0.1317\n",
      "Epoch 202/600\n",
      "426/426 [==============================] - 0s 247us/sample - loss: 0.0383 - val_loss: 0.1364\n",
      "Epoch 203/600\n",
      "426/426 [==============================] - 0s 249us/sample - loss: 0.0385 - val_loss: 0.1280\n",
      "Epoch 204/600\n",
      "426/426 [==============================] - 0s 277us/sample - loss: 0.0363 - val_loss: 0.1317\n",
      "Epoch 205/600\n",
      "426/426 [==============================] - 0s 254us/sample - loss: 0.0373 - val_loss: 0.1243\n",
      "Epoch 206/600\n",
      "426/426 [==============================] - 0s 261us/sample - loss: 0.0374 - val_loss: 0.1406\n",
      "Epoch 207/600\n",
      "426/426 [==============================] - 0s 254us/sample - loss: 0.0373 - val_loss: 0.1247\n",
      "Epoch 208/600\n",
      "426/426 [==============================] - 0s 239us/sample - loss: 0.0368 - val_loss: 0.1303\n",
      "Epoch 209/600\n",
      "426/426 [==============================] - 0s 228us/sample - loss: 0.0356 - val_loss: 0.1331\n",
      "Epoch 210/600\n",
      "426/426 [==============================] - 0s 228us/sample - loss: 0.0380 - val_loss: 0.1354\n",
      "Epoch 211/600\n",
      "426/426 [==============================] - 0s 237us/sample - loss: 0.0355 - val_loss: 0.1245\n",
      "Epoch 212/600\n",
      "426/426 [==============================] - 0s 228us/sample - loss: 0.0380 - val_loss: 0.1312\n",
      "Epoch 213/600\n",
      "426/426 [==============================] - 0s 235us/sample - loss: 0.0367 - val_loss: 0.1278\n",
      "Epoch 214/600\n",
      "426/426 [==============================] - 0s 209us/sample - loss: 0.0383 - val_loss: 0.1312\n",
      "Epoch 215/600\n",
      "426/426 [==============================] - 0s 204us/sample - loss: 0.0365 - val_loss: 0.1293\n",
      "Epoch 216/600\n",
      "426/426 [==============================] - 0s 209us/sample - loss: 0.0354 - val_loss: 0.1290\n",
      "Epoch 217/600\n",
      "426/426 [==============================] - 0s 217us/sample - loss: 0.0354 - val_loss: 0.1395\n",
      "Epoch 218/600\n",
      "426/426 [==============================] - 0s 214us/sample - loss: 0.0354 - val_loss: 0.1246\n",
      "Epoch 219/600\n",
      "426/426 [==============================] - 0s 228us/sample - loss: 0.0433 - val_loss: 0.1407\n",
      "Epoch 220/600\n",
      "426/426 [==============================] - 0s 228us/sample - loss: 0.0428 - val_loss: 0.1272\n",
      "Epoch 221/600\n",
      "426/426 [==============================] - 0s 225us/sample - loss: 0.0469 - val_loss: 0.1349\n",
      "Epoch 222/600\n",
      "426/426 [==============================] - 0s 221us/sample - loss: 0.0373 - val_loss: 0.1297\n",
      "Epoch 223/600\n",
      "426/426 [==============================] - 0s 228us/sample - loss: 0.0369 - val_loss: 0.1300\n",
      "Epoch 224/600\n",
      "426/426 [==============================] - 0s 209us/sample - loss: 0.0358 - val_loss: 0.1325\n",
      "Epoch 225/600\n",
      "426/426 [==============================] - 0s 223us/sample - loss: 0.0346 - val_loss: 0.1281\n",
      "Epoch 226/600\n",
      "426/426 [==============================] - 0s 209us/sample - loss: 0.0345 - val_loss: 0.1352\n",
      "Epoch 227/600\n",
      "426/426 [==============================] - 0s 211us/sample - loss: 0.0344 - val_loss: 0.1337\n",
      "Epoch 228/600\n",
      "426/426 [==============================] - 0s 209us/sample - loss: 0.0339 - val_loss: 0.1306\n",
      "Epoch 229/600\n",
      "426/426 [==============================] - 0s 214us/sample - loss: 0.0394 - val_loss: 0.1360\n",
      "Epoch 230/600\n",
      "426/426 [==============================] - 0s 211us/sample - loss: 0.0392 - val_loss: 0.1312\n",
      "Epoch 231/600\n",
      "426/426 [==============================] - 0s 211us/sample - loss: 0.0339 - val_loss: 0.1294\n",
      "Epoch 232/600\n",
      "426/426 [==============================] - 0s 212us/sample - loss: 0.0342 - val_loss: 0.1358\n",
      "Epoch 233/600\n",
      "426/426 [==============================] - 0s 214us/sample - loss: 0.0340 - val_loss: 0.1323\n",
      "Epoch 234/600\n",
      "426/426 [==============================] - 0s 221us/sample - loss: 0.0343 - val_loss: 0.1291\n",
      "Epoch 235/600\n",
      "426/426 [==============================] - 0s 201us/sample - loss: 0.0359 - val_loss: 0.1293\n",
      "Epoch 236/600\n",
      "426/426 [==============================] - 0s 228us/sample - loss: 0.0385 - val_loss: 0.1340\n",
      "Epoch 237/600\n",
      "426/426 [==============================] - 0s 225us/sample - loss: 0.0373 - val_loss: 0.1319\n",
      "Epoch 238/600\n",
      "426/426 [==============================] - 0s 225us/sample - loss: 0.0334 - val_loss: 0.1211\n",
      "Epoch 239/600\n",
      "426/426 [==============================] - 0s 211us/sample - loss: 0.0359 - val_loss: 0.1401\n",
      "Epoch 240/600\n",
      "426/426 [==============================] - 0s 214us/sample - loss: 0.0336 - val_loss: 0.1287\n",
      "Epoch 241/600\n",
      "426/426 [==============================] - 0s 216us/sample - loss: 0.0370 - val_loss: 0.1237\n",
      "Epoch 242/600\n",
      "426/426 [==============================] - 0s 216us/sample - loss: 0.0347 - val_loss: 0.1450\n",
      "Epoch 243/600\n",
      "426/426 [==============================] - 0s 216us/sample - loss: 0.0345 - val_loss: 0.1332\n",
      "Epoch 244/600\n",
      "426/426 [==============================] - 0s 211us/sample - loss: 0.0343 - val_loss: 0.1393\n",
      "Epoch 245/600\n",
      "426/426 [==============================] - 0s 209us/sample - loss: 0.0348 - val_loss: 0.1283\n",
      "Epoch 246/600\n",
      "426/426 [==============================] - 0s 218us/sample - loss: 0.0339 - val_loss: 0.1369\n",
      "Epoch 247/600\n",
      "426/426 [==============================] - 0s 225us/sample - loss: 0.0345 - val_loss: 0.1284\n",
      "Epoch 248/600\n",
      "426/426 [==============================] - 0s 222us/sample - loss: 0.0452 - val_loss: 0.1375\n",
      "Epoch 249/600\n",
      "426/426 [==============================] - 0s 213us/sample - loss: 0.0401 - val_loss: 0.1291\n",
      "Epoch 250/600\n",
      "426/426 [==============================] - 0s 214us/sample - loss: 0.0351 - val_loss: 0.1364\n",
      "Epoch 251/600\n",
      "426/426 [==============================] - 0s 221us/sample - loss: 0.0374 - val_loss: 0.1361\n",
      "Epoch 252/600\n",
      "426/426 [==============================] - 0s 211us/sample - loss: 0.0346 - val_loss: 0.1391\n",
      "Epoch 253/600\n",
      "426/426 [==============================] - 0s 214us/sample - loss: 0.0446 - val_loss: 0.1248\n",
      "Epoch 254/600\n",
      "426/426 [==============================] - 0s 218us/sample - loss: 0.0431 - val_loss: 0.1631\n",
      "Epoch 255/600\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.007 - 0s 207us/sample - loss: 0.0383 - val_loss: 0.1226\n",
      "Epoch 256/600\n",
      "426/426 [==============================] - 0s 209us/sample - loss: 0.0384 - val_loss: 0.1346\n",
      "Epoch 257/600\n",
      "426/426 [==============================] - 0s 202us/sample - loss: 0.0371 - val_loss: 0.1289\n",
      "Epoch 258/600\n",
      "426/426 [==============================] - 0s 204us/sample - loss: 0.0335 - val_loss: 0.1325\n",
      "Epoch 259/600\n",
      "426/426 [==============================] - 0s 196us/sample - loss: 0.0323 - val_loss: 0.1415\n",
      "Epoch 260/600\n",
      "426/426 [==============================] - 0s 254us/sample - loss: 0.0325 - val_loss: 0.1467\n",
      "Epoch 261/600\n",
      "426/426 [==============================] - 0s 230us/sample - loss: 0.0354 - val_loss: 0.1256\n",
      "Epoch 262/600\n",
      "426/426 [==============================] - 0s 203us/sample - loss: 0.0418 - val_loss: 0.1509\n",
      "Epoch 263/600\n",
      "426/426 [==============================] - 0s 212us/sample - loss: 0.0401 - val_loss: 0.1326\n",
      "Epoch 264/600\n",
      "426/426 [==============================] - 0s 239us/sample - loss: 0.0370 - val_loss: 0.1367\n",
      "Epoch 265/600\n",
      "426/426 [==============================] - 0s 207us/sample - loss: 0.0319 - val_loss: 0.1443\n",
      "Epoch 266/600\n",
      "426/426 [==============================] - 0s 201us/sample - loss: 0.0318 - val_loss: 0.1318\n",
      "Epoch 267/600\n",
      "426/426 [==============================] - 0s 221us/sample - loss: 0.0326 - val_loss: 0.1461\n",
      "Epoch 268/600\n",
      "426/426 [==============================] - 0s 207us/sample - loss: 0.0328 - val_loss: 0.1345\n",
      "Epoch 269/600\n",
      "426/426 [==============================] - 0s 224us/sample - loss: 0.0334 - val_loss: 0.1440\n",
      "Epoch 270/600\n",
      "426/426 [==============================] - 0s 210us/sample - loss: 0.0341 - val_loss: 0.1443\n",
      "Epoch 271/600\n",
      "426/426 [==============================] - 0s 203us/sample - loss: 0.0328 - val_loss: 0.1314\n",
      "Epoch 272/600\n",
      "426/426 [==============================] - 0s 223us/sample - loss: 0.0370 - val_loss: 0.1421\n",
      "Epoch 273/600\n",
      "426/426 [==============================] - 0s 207us/sample - loss: 0.0322 - val_loss: 0.1372\n",
      "Epoch 274/600\n",
      "426/426 [==============================] - 0s 217us/sample - loss: 0.0308 - val_loss: 0.1400\n",
      "Epoch 275/600\n",
      "426/426 [==============================] - 0s 210us/sample - loss: 0.0315 - val_loss: 0.1369\n",
      "Epoch 276/600\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.082 - 0s 207us/sample - loss: 0.0312 - val_loss: 0.1392\n",
      "Epoch 277/600\n",
      "426/426 [==============================] - 0s 225us/sample - loss: 0.0316 - val_loss: 0.1381\n",
      "Epoch 278/600\n",
      "426/426 [==============================] - 0s 228us/sample - loss: 0.0304 - val_loss: 0.1312\n",
      "Epoch 279/600\n",
      "426/426 [==============================] - 0s 223us/sample - loss: 0.0349 - val_loss: 0.1604\n",
      "Epoch 280/600\n",
      "426/426 [==============================] - 0s 209us/sample - loss: 0.0319 - val_loss: 0.1291\n",
      "Epoch 281/600\n",
      "426/426 [==============================] - 0s 211us/sample - loss: 0.0339 - val_loss: 0.1339\n",
      "Epoch 282/600\n",
      "426/426 [==============================] - 0s 209us/sample - loss: 0.0359 - val_loss: 0.1336\n",
      "Epoch 283/600\n",
      "426/426 [==============================] - 0s 228us/sample - loss: 0.0323 - val_loss: 0.1474\n",
      "Epoch 284/600\n",
      "426/426 [==============================] - 0s 211us/sample - loss: 0.0305 - val_loss: 0.1326\n",
      "Epoch 285/600\n",
      "426/426 [==============================] - 0s 195us/sample - loss: 0.0330 - val_loss: 0.1471\n",
      "Epoch 286/600\n",
      "426/426 [==============================] - 0s 237us/sample - loss: 0.0326 - val_loss: 0.1319\n",
      "Epoch 287/600\n",
      "426/426 [==============================] - 0s 207us/sample - loss: 0.0318 - val_loss: 0.1352\n",
      "Epoch 288/600\n",
      "426/426 [==============================] - 0s 207us/sample - loss: 0.0306 - val_loss: 0.1358\n",
      "Epoch 289/600\n",
      "426/426 [==============================] - 0s 222us/sample - loss: 0.0303 - val_loss: 0.1514\n",
      "Epoch 290/600\n",
      "426/426 [==============================] - 0s 225us/sample - loss: 0.0317 - val_loss: 0.1371\n",
      "Epoch 291/600\n",
      "426/426 [==============================] - 0s 214us/sample - loss: 0.0312 - val_loss: 0.1404\n",
      "Epoch 292/600\n",
      "426/426 [==============================] - 0s 207us/sample - loss: 0.0300 - val_loss: 0.1282\n",
      "Epoch 293/600\n",
      "426/426 [==============================] - 0s 235us/sample - loss: 0.0344 - val_loss: 0.1518\n",
      "Epoch 294/600\n",
      "426/426 [==============================] - 0s 209us/sample - loss: 0.0300 - val_loss: 0.1307\n",
      "Epoch 295/600\n",
      "426/426 [==============================] - 0s 211us/sample - loss: 0.0308 - val_loss: 0.1376\n",
      "Epoch 296/600\n",
      "426/426 [==============================] - 0s 207us/sample - loss: 0.0312 - val_loss: 0.1506\n",
      "Epoch 297/600\n",
      "426/426 [==============================] - 0s 223us/sample - loss: 0.0313 - val_loss: 0.1389\n",
      "Epoch 298/600\n",
      "426/426 [==============================] - 0s 211us/sample - loss: 0.0346 - val_loss: 0.1370\n",
      "Epoch 299/600\n",
      "426/426 [==============================] - 0s 202us/sample - loss: 0.0330 - val_loss: 0.1364\n",
      "Epoch 300/600\n",
      "426/426 [==============================] - 0s 200us/sample - loss: 0.0341 - val_loss: 0.1538\n",
      "Epoch 301/600\n",
      "426/426 [==============================] - 0s 216us/sample - loss: 0.0314 - val_loss: 0.1423\n",
      "Epoch 302/600\n",
      "426/426 [==============================] - 0s 200us/sample - loss: 0.0323 - val_loss: 0.1434\n",
      "Epoch 303/600\n",
      "426/426 [==============================] - 0s 228us/sample - loss: 0.0292 - val_loss: 0.1339\n",
      "Epoch 304/600\n",
      "426/426 [==============================] - 0s 207us/sample - loss: 0.0309 - val_loss: 0.1421\n",
      "Epoch 305/600\n",
      "426/426 [==============================] - 0s 197us/sample - loss: 0.0302 - val_loss: 0.1529\n",
      "Epoch 306/600\n",
      "426/426 [==============================] - 0s 198us/sample - loss: 0.0302 - val_loss: 0.1377\n",
      "Epoch 307/600\n",
      "426/426 [==============================] - 0s 212us/sample - loss: 0.0304 - val_loss: 0.1449\n",
      "Epoch 308/600\n",
      "426/426 [==============================] - 0s 235us/sample - loss: 0.0292 - val_loss: 0.1461\n",
      "Epoch 309/600\n",
      "426/426 [==============================] - 0s 197us/sample - loss: 0.0336 - val_loss: 0.1505\n",
      "Epoch 310/600\n",
      "426/426 [==============================] - 0s 230us/sample - loss: 0.0549 - val_loss: 0.1291\n",
      "Epoch 311/600\n",
      "426/426 [==============================] - 0s 207us/sample - loss: 0.0505 - val_loss: 0.1715\n",
      "Epoch 312/600\n",
      "426/426 [==============================] - 0s 195us/sample - loss: 0.0377 - val_loss: 0.1363\n",
      "Epoch 313/600\n",
      "426/426 [==============================] - 0s 207us/sample - loss: 0.0304 - val_loss: 0.1419\n",
      "Epoch 314/600\n",
      "426/426 [==============================] - 0s 204us/sample - loss: 0.0298 - val_loss: 0.1391\n",
      "Epoch 315/600\n",
      "426/426 [==============================] - 0s 200us/sample - loss: 0.0284 - val_loss: 0.1474\n",
      "Epoch 316/600\n",
      "426/426 [==============================] - 0s 225us/sample - loss: 0.0290 - val_loss: 0.1361\n",
      "Epoch 317/600\n",
      "426/426 [==============================] - 0s 202us/sample - loss: 0.0283 - val_loss: 0.1517\n",
      "Epoch 318/600\n",
      "426/426 [==============================] - 0s 207us/sample - loss: 0.0296 - val_loss: 0.1369\n",
      "Epoch 319/600\n",
      "426/426 [==============================] - 0s 210us/sample - loss: 0.0288 - val_loss: 0.1456\n",
      "Epoch 320/600\n",
      "426/426 [==============================] - 0s 192us/sample - loss: 0.0288 - val_loss: 0.1459\n",
      "Epoch 321/600\n",
      "426/426 [==============================] - 0s 209us/sample - loss: 0.0294 - val_loss: 0.1463\n",
      "Epoch 322/600\n",
      "426/426 [==============================] - 0s 230us/sample - loss: 0.0344 - val_loss: 0.1684\n",
      "Epoch 323/600\n",
      "426/426 [==============================] - 0s 214us/sample - loss: 0.0302 - val_loss: 0.1340\n",
      "Epoch 324/600\n",
      "426/426 [==============================] - 0s 209us/sample - loss: 0.0319 - val_loss: 0.1421\n",
      "Epoch 325/600\n",
      "426/426 [==============================] - 0s 221us/sample - loss: 0.0361 - val_loss: 0.1390\n",
      "Epoch 326/600\n",
      "426/426 [==============================] - 0s 214us/sample - loss: 0.0343 - val_loss: 0.1535\n",
      "Epoch 327/600\n",
      "426/426 [==============================] - 0s 204us/sample - loss: 0.0281 - val_loss: 0.1424\n",
      "Epoch 328/600\n",
      "426/426 [==============================] - 0s 223us/sample - loss: 0.0283 - val_loss: 0.1410\n",
      "Epoch 329/600\n",
      "426/426 [==============================] - 0s 226us/sample - loss: 0.0316 - val_loss: 0.1475\n",
      "Epoch 330/600\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.018 - 0s 202us/sample - loss: 0.0298 - val_loss: 0.1385\n",
      "Epoch 331/600\n",
      "426/426 [==============================] - 0s 230us/sample - loss: 0.0304 - val_loss: 0.1372\n",
      "Epoch 332/600\n",
      "426/426 [==============================] - 0s 211us/sample - loss: 0.0355 - val_loss: 0.1527\n",
      "Epoch 333/600\n",
      "426/426 [==============================] - 0s 202us/sample - loss: 0.0281 - val_loss: 0.1441\n",
      "Epoch 334/600\n",
      "426/426 [==============================] - 0s 230us/sample - loss: 0.0296 - val_loss: 0.1333\n",
      "Epoch 335/600\n",
      "426/426 [==============================] - 0s 216us/sample - loss: 0.0342 - val_loss: 0.1575\n",
      "Epoch 336/600\n",
      "426/426 [==============================] - 0s 207us/sample - loss: 0.0330 - val_loss: 0.1331\n",
      "Epoch 337/600\n",
      "426/426 [==============================] - 0s 218us/sample - loss: 0.0322 - val_loss: 0.1468\n",
      "Epoch 338/600\n",
      "426/426 [==============================] - 0s 197us/sample - loss: 0.0285 - val_loss: 0.1418\n",
      "Epoch 339/600\n",
      "426/426 [==============================] - 0s 211us/sample - loss: 0.0278 - val_loss: 0.1449\n",
      "Epoch 340/600\n",
      "426/426 [==============================] - 0s 244us/sample - loss: 0.0307 - val_loss: 0.1471\n",
      "Epoch 341/600\n",
      "426/426 [==============================] - 0s 195us/sample - loss: 0.0279 - val_loss: 0.1425\n",
      "Epoch 342/600\n",
      "426/426 [==============================] - 0s 221us/sample - loss: 0.0288 - val_loss: 0.1387\n",
      "Epoch 343/600\n",
      "426/426 [==============================] - 0s 214us/sample - loss: 0.0292 - val_loss: 0.1559\n",
      "Epoch 344/600\n",
      "426/426 [==============================] - 0s 200us/sample - loss: 0.0373 - val_loss: 0.1376\n",
      "Epoch 345/600\n",
      "426/426 [==============================] - 0s 228us/sample - loss: 0.0331 - val_loss: 0.1416\n",
      "Epoch 346/600\n",
      "426/426 [==============================] - 0s 207us/sample - loss: 0.0360 - val_loss: 0.1448\n",
      "Epoch 347/600\n",
      "426/426 [==============================] - 0s 221us/sample - loss: 0.0303 - val_loss: 0.1493\n",
      "Epoch 348/600\n",
      "426/426 [==============================] - 0s 204us/sample - loss: 0.0311 - val_loss: 0.1375\n",
      "Epoch 349/600\n",
      "426/426 [==============================] - 0s 200us/sample - loss: 0.0283 - val_loss: 0.1405\n",
      "Epoch 350/600\n",
      "426/426 [==============================] - 0s 254us/sample - loss: 0.0272 - val_loss: 0.1472\n",
      "Epoch 351/600\n",
      "426/426 [==============================] - 0s 214us/sample - loss: 0.0274 - val_loss: 0.1443\n",
      "Epoch 352/600\n",
      "426/426 [==============================] - 0s 207us/sample - loss: 0.0269 - val_loss: 0.1413\n",
      "Epoch 353/600\n",
      "426/426 [==============================] - 0s 216us/sample - loss: 0.0316 - val_loss: 0.1471\n",
      "Epoch 354/600\n",
      "426/426 [==============================] - 0s 225us/sample - loss: 0.0299 - val_loss: 0.1553\n",
      "Epoch 355/600\n",
      "426/426 [==============================] - 0s 190us/sample - loss: 0.0292 - val_loss: 0.1435\n",
      "Epoch 356/600\n",
      "426/426 [==============================] - 0s 221us/sample - loss: 0.0272 - val_loss: 0.1469\n",
      "Epoch 357/600\n",
      "426/426 [==============================] - 0s 204us/sample - loss: 0.0360 - val_loss: 0.1539\n",
      "Epoch 358/600\n",
      "426/426 [==============================] - 0s 218us/sample - loss: 0.0268 - val_loss: 0.1609\n",
      "Epoch 359/600\n",
      "426/426 [==============================] - 0s 195us/sample - loss: 0.0278 - val_loss: 0.1420\n",
      "Epoch 360/600\n",
      "426/426 [==============================] - 0s 204us/sample - loss: 0.0270 - val_loss: 0.1610\n",
      "Epoch 361/600\n",
      "426/426 [==============================] - 0s 191us/sample - loss: 0.0279 - val_loss: 0.1388\n",
      "Epoch 362/600\n",
      "426/426 [==============================] - 0s 202us/sample - loss: 0.0291 - val_loss: 0.1738\n",
      "Epoch 363/600\n",
      "426/426 [==============================] - 0s 191us/sample - loss: 0.0360 - val_loss: 0.1405\n",
      "Epoch 364/600\n",
      "426/426 [==============================] - 0s 200us/sample - loss: 0.0318 - val_loss: 0.1489\n",
      "Epoch 365/600\n",
      "426/426 [==============================] - 0s 205us/sample - loss: 0.0265 - val_loss: 0.1499\n",
      "Epoch 366/600\n",
      "426/426 [==============================] - 0s 195us/sample - loss: 0.0262 - val_loss: 0.1489\n",
      "Epoch 367/600\n",
      "426/426 [==============================] - 0s 216us/sample - loss: 0.0275 - val_loss: 0.1572\n",
      "Epoch 368/600\n",
      "426/426 [==============================] - 0s 197us/sample - loss: 0.0273 - val_loss: 0.1480\n",
      "Epoch 369/600\n",
      "426/426 [==============================] - 0s 221us/sample - loss: 0.0256 - val_loss: 0.1545\n",
      "Epoch 370/600\n",
      "426/426 [==============================] - 0s 197us/sample - loss: 0.0259 - val_loss: 0.1491\n",
      "Epoch 371/600\n",
      "426/426 [==============================] - 0s 223us/sample - loss: 0.0315 - val_loss: 0.1481\n",
      "Epoch 372/600\n",
      "426/426 [==============================] - 0s 242us/sample - loss: 0.0255 - val_loss: 0.1591\n",
      "Epoch 373/600\n",
      "426/426 [==============================] - 0s 190us/sample - loss: 0.0254 - val_loss: 0.1487\n",
      "Epoch 374/600\n",
      "426/426 [==============================] - 0s 207us/sample - loss: 0.0271 - val_loss: 0.1597\n",
      "Epoch 375/600\n",
      "426/426 [==============================] - 0s 171us/sample - loss: 0.0276 - val_loss: 0.1602\n",
      "Epoch 376/600\n",
      "426/426 [==============================] - 0s 246us/sample - loss: 0.0270 - val_loss: 0.1495\n",
      "Epoch 377/600\n",
      "426/426 [==============================] - 0s 207us/sample - loss: 0.0277 - val_loss: 0.1596\n",
      "Epoch 378/600\n",
      "426/426 [==============================] - 0s 211us/sample - loss: 0.0259 - val_loss: 0.1634\n",
      "Epoch 379/600\n",
      "426/426 [==============================] - 0s 200us/sample - loss: 0.0261 - val_loss: 0.1568\n",
      "Epoch 380/600\n",
      "426/426 [==============================] - 0s 207us/sample - loss: 0.0289 - val_loss: 0.1540\n",
      "Epoch 381/600\n",
      "426/426 [==============================] - 0s 193us/sample - loss: 0.0256 - val_loss: 0.1524\n",
      "Epoch 382/600\n",
      "426/426 [==============================] - 0s 224us/sample - loss: 0.0256 - val_loss: 0.1480\n",
      "Epoch 383/600\n",
      "426/426 [==============================] - 0s 197us/sample - loss: 0.0266 - val_loss: 0.1646\n",
      "Epoch 384/600\n",
      "426/426 [==============================] - 0s 228us/sample - loss: 0.0251 - val_loss: 0.1506\n",
      "Epoch 385/600\n",
      "426/426 [==============================] - 0s 195us/sample - loss: 0.0305 - val_loss: 0.1580\n",
      "Epoch 386/600\n",
      "426/426 [==============================] - 0s 204us/sample - loss: 0.0287 - val_loss: 0.1601\n",
      "Epoch 387/600\n",
      "426/426 [==============================] - 0s 197us/sample - loss: 0.0262 - val_loss: 0.1511\n",
      "Epoch 388/600\n",
      "426/426 [==============================] - 0s 192us/sample - loss: 0.0256 - val_loss: 0.1591\n",
      "Epoch 389/600\n",
      "426/426 [==============================] - 0s 195us/sample - loss: 0.0263 - val_loss: 0.1556\n",
      "Epoch 390/600\n",
      "426/426 [==============================] - 0s 196us/sample - loss: 0.0253 - val_loss: 0.1450\n",
      "Epoch 391/600\n",
      "426/426 [==============================] - 0s 207us/sample - loss: 0.0409 - val_loss: 0.1556\n",
      "Epoch 392/600\n",
      "426/426 [==============================] - 0s 199us/sample - loss: 0.0304 - val_loss: 0.1480\n",
      "Epoch 393/600\n",
      "426/426 [==============================] - 0s 211us/sample - loss: 0.0262 - val_loss: 0.1480\n",
      "Epoch 394/600\n",
      "426/426 [==============================] - 0s 192us/sample - loss: 0.0242 - val_loss: 0.1616\n",
      "Epoch 395/600\n",
      "426/426 [==============================] - 0s 197us/sample - loss: 0.0250 - val_loss: 0.1454\n",
      "Epoch 396/600\n",
      "426/426 [==============================] - 0s 188us/sample - loss: 0.0237 - val_loss: 0.1724\n",
      "Epoch 397/600\n",
      "426/426 [==============================] - 0s 202us/sample - loss: 0.0267 - val_loss: 0.1492\n",
      "Epoch 398/600\n",
      "426/426 [==============================] - 0s 223us/sample - loss: 0.0236 - val_loss: 0.1622\n",
      "Epoch 399/600\n",
      "426/426 [==============================] - 0s 197us/sample - loss: 0.0267 - val_loss: 0.1531\n",
      "Epoch 400/600\n",
      "426/426 [==============================] - 0s 200us/sample - loss: 0.0252 - val_loss: 0.1630\n",
      "Epoch 401/600\n",
      "426/426 [==============================] - 0s 202us/sample - loss: 0.0242 - val_loss: 0.1584\n",
      "Epoch 402/600\n",
      "426/426 [==============================] - 0s 200us/sample - loss: 0.0245 - val_loss: 0.1554\n",
      "Epoch 403/600\n",
      "426/426 [==============================] - 0s 204us/sample - loss: 0.0279 - val_loss: 0.1400\n",
      "Epoch 404/600\n",
      "426/426 [==============================] - 0s 192us/sample - loss: 0.0272 - val_loss: 0.1520\n",
      "Epoch 405/600\n",
      "426/426 [==============================] - 0s 221us/sample - loss: 0.0244 - val_loss: 0.1616\n",
      "Epoch 406/600\n",
      "426/426 [==============================] - 0s 200us/sample - loss: 0.0244 - val_loss: 0.1772\n",
      "Epoch 407/600\n",
      "426/426 [==============================] - 0s 209us/sample - loss: 0.0251 - val_loss: 0.1683\n",
      "Epoch 408/600\n",
      "426/426 [==============================] - 0s 192us/sample - loss: 0.0244 - val_loss: 0.1706\n",
      "Epoch 409/600\n",
      "426/426 [==============================] - 0s 200us/sample - loss: 0.0235 - val_loss: 0.1537\n",
      "Epoch 410/600\n",
      "426/426 [==============================] - 0s 190us/sample - loss: 0.0242 - val_loss: 0.1671\n",
      "Epoch 411/600\n",
      "426/426 [==============================] - 0s 204us/sample - loss: 0.0239 - val_loss: 0.1669\n",
      "Epoch 412/600\n",
      "426/426 [==============================] - 0s 190us/sample - loss: 0.0243 - val_loss: 0.1738\n",
      "Epoch 413/600\n",
      "426/426 [==============================] - 0s 205us/sample - loss: 0.0265 - val_loss: 0.1640\n",
      "Epoch 414/600\n",
      "426/426 [==============================] - 0s 190us/sample - loss: 0.0267 - val_loss: 0.1537\n",
      "Epoch 415/600\n",
      "426/426 [==============================] - 0s 202us/sample - loss: 0.0260 - val_loss: 0.1596\n",
      "Epoch 416/600\n",
      "426/426 [==============================] - 0s 190us/sample - loss: 0.0231 - val_loss: 0.1529\n",
      "Epoch 417/600\n",
      "426/426 [==============================] - 0s 197us/sample - loss: 0.0240 - val_loss: 0.1558\n",
      "Epoch 418/600\n",
      "426/426 [==============================] - 0s 190us/sample - loss: 0.0237 - val_loss: 0.1708\n",
      "Epoch 419/600\n",
      "426/426 [==============================] - 0s 200us/sample - loss: 0.0225 - val_loss: 0.1498\n",
      "Epoch 420/600\n",
      "426/426 [==============================] - 0s 207us/sample - loss: 0.0248 - val_loss: 0.1827\n",
      "Epoch 421/600\n",
      "426/426 [==============================] - 0s 228us/sample - loss: 0.0233 - val_loss: 0.1626\n",
      "Epoch 422/600\n",
      "426/426 [==============================] - 0s 204us/sample - loss: 0.0260 - val_loss: 0.1542\n",
      "Epoch 423/600\n",
      "426/426 [==============================] - 0s 225us/sample - loss: 0.0258 - val_loss: 0.1721\n",
      "Epoch 424/600\n",
      "426/426 [==============================] - 0s 195us/sample - loss: 0.0251 - val_loss: 0.1523\n",
      "Epoch 425/600\n",
      "426/426 [==============================] - 0s 200us/sample - loss: 0.0241 - val_loss: 0.1754\n",
      "Epoch 426/600\n",
      "426/426 [==============================] - 0s 190us/sample - loss: 0.0369 - val_loss: 0.1448\n",
      "Epoch 427/600\n",
      "426/426 [==============================] - 0s 200us/sample - loss: 0.0273 - val_loss: 0.1725\n",
      "Epoch 428/600\n",
      "426/426 [==============================] - 0s 192us/sample - loss: 0.0265 - val_loss: 0.1595\n",
      "Epoch 429/600\n",
      "426/426 [==============================] - 0s 190us/sample - loss: 0.0245 - val_loss: 0.1648\n",
      "Epoch 430/600\n",
      "426/426 [==============================] - 0s 216us/sample - loss: 0.0309 - val_loss: 0.1616\n",
      "Epoch 431/600\n",
      "426/426 [==============================] - 0s 192us/sample - loss: 0.0228 - val_loss: 0.1771\n",
      "Epoch 432/600\n",
      "426/426 [==============================] - 0s 243us/sample - loss: 0.0255 - val_loss: 0.1706\n",
      "Epoch 433/600\n",
      "426/426 [==============================] - 0s 202us/sample - loss: 0.0243 - val_loss: 0.1678\n",
      "Epoch 434/600\n",
      "426/426 [==============================] - 0s 225us/sample - loss: 0.0226 - val_loss: 0.1694\n",
      "Epoch 435/600\n",
      "426/426 [==============================] - 0s 190us/sample - loss: 0.0219 - val_loss: 0.1623\n",
      "Epoch 436/600\n",
      "426/426 [==============================] - 0s 202us/sample - loss: 0.0215 - val_loss: 0.1709\n",
      "Epoch 437/600\n",
      "426/426 [==============================] - 0s 223us/sample - loss: 0.0225 - val_loss: 0.1647\n",
      "Epoch 438/600\n",
      "426/426 [==============================] - 0s 195us/sample - loss: 0.0229 - val_loss: 0.1680\n",
      "Epoch 439/600\n",
      "426/426 [==============================] - 0s 203us/sample - loss: 0.0232 - val_loss: 0.1716\n",
      "Epoch 440/600\n",
      "426/426 [==============================] - 0s 192us/sample - loss: 0.0289 - val_loss: 0.1519\n",
      "Epoch 441/600\n",
      "426/426 [==============================] - 0s 190us/sample - loss: 0.0293 - val_loss: 0.1915\n",
      "Epoch 442/600\n",
      "426/426 [==============================] - 0s 223us/sample - loss: 0.0255 - val_loss: 0.1601\n",
      "Epoch 443/600\n",
      "426/426 [==============================] - 0s 188us/sample - loss: 0.0221 - val_loss: 0.1712\n",
      "Epoch 444/600\n",
      "426/426 [==============================] - 0s 203us/sample - loss: 0.0220 - val_loss: 0.1650\n",
      "Epoch 445/600\n",
      "426/426 [==============================] - 0s 225us/sample - loss: 0.0247 - val_loss: 0.1694\n",
      "Epoch 446/600\n",
      "426/426 [==============================] - 0s 200us/sample - loss: 0.0235 - val_loss: 0.1783\n",
      "Epoch 447/600\n",
      "426/426 [==============================] - 0s 189us/sample - loss: 0.0258 - val_loss: 0.1604\n",
      "Epoch 448/600\n",
      "426/426 [==============================] - 0s 193us/sample - loss: 0.0228 - val_loss: 0.1733\n",
      "Epoch 449/600\n",
      "426/426 [==============================] - 0s 207us/sample - loss: 0.0222 - val_loss: 0.1729\n",
      "Epoch 450/600\n",
      "426/426 [==============================] - 0s 193us/sample - loss: 0.0223 - val_loss: 0.1891\n",
      "Epoch 451/600\n",
      "426/426 [==============================] - 0s 202us/sample - loss: 0.0244 - val_loss: 0.1750\n",
      "Epoch 452/600\n",
      "426/426 [==============================] - 0s 193us/sample - loss: 0.0224 - val_loss: 0.1615\n",
      "Epoch 453/600\n",
      "426/426 [==============================] - 0s 207us/sample - loss: 0.0272 - val_loss: 0.1706\n",
      "Epoch 454/600\n",
      "426/426 [==============================] - 0s 207us/sample - loss: 0.0216 - val_loss: 0.1668\n",
      "Epoch 455/600\n",
      "426/426 [==============================] - 0s 204us/sample - loss: 0.0245 - val_loss: 0.1761\n",
      "Epoch 456/600\n",
      "426/426 [==============================] - 0s 200us/sample - loss: 0.0206 - val_loss: 0.1652\n",
      "Epoch 457/600\n",
      "426/426 [==============================] - 0s 197us/sample - loss: 0.0223 - val_loss: 0.1918\n",
      "Epoch 458/600\n",
      "426/426 [==============================] - 0s 221us/sample - loss: 0.0225 - val_loss: 0.1577\n",
      "Epoch 459/600\n",
      "426/426 [==============================] - 0s 190us/sample - loss: 0.0279 - val_loss: 0.1900\n",
      "Epoch 460/600\n",
      "426/426 [==============================] - 0s 202us/sample - loss: 0.0224 - val_loss: 0.1676\n",
      "Epoch 461/600\n",
      "426/426 [==============================] - 0s 200us/sample - loss: 0.0211 - val_loss: 0.1806\n",
      "Epoch 462/600\n",
      "426/426 [==============================] - 0s 185us/sample - loss: 0.0216 - val_loss: 0.1729\n",
      "Epoch 463/600\n",
      "426/426 [==============================] - 0s 200us/sample - loss: 0.0217 - val_loss: 0.1708\n",
      "Epoch 464/600\n",
      "426/426 [==============================] - 0s 190us/sample - loss: 0.0216 - val_loss: 0.1889\n",
      "Epoch 465/600\n",
      "426/426 [==============================] - 0s 204us/sample - loss: 0.0227 - val_loss: 0.1672\n",
      "Epoch 466/600\n",
      "426/426 [==============================] - 0s 193us/sample - loss: 0.0234 - val_loss: 0.1971\n",
      "Epoch 467/600\n",
      "426/426 [==============================] - 0s 209us/sample - loss: 0.0229 - val_loss: 0.1609\n",
      "Epoch 468/600\n",
      "426/426 [==============================] - 0s 190us/sample - loss: 0.0227 - val_loss: 0.1817\n",
      "Epoch 469/600\n",
      "426/426 [==============================] - 0s 202us/sample - loss: 0.0204 - val_loss: 0.1731\n",
      "Epoch 470/600\n",
      "426/426 [==============================] - 0s 195us/sample - loss: 0.0199 - val_loss: 0.1727\n",
      "Epoch 471/600\n",
      "426/426 [==============================] - 0s 190us/sample - loss: 0.0221 - val_loss: 0.1829\n",
      "Epoch 472/600\n",
      "426/426 [==============================] - 0s 204us/sample - loss: 0.0293 - val_loss: 0.1890\n",
      "Epoch 473/600\n",
      "426/426 [==============================] - 0s 190us/sample - loss: 0.0275 - val_loss: 0.1659\n",
      "Epoch 474/600\n",
      "426/426 [==============================] - 0s 204us/sample - loss: 0.0200 - val_loss: 0.1811\n",
      "Epoch 475/600\n",
      "426/426 [==============================] - 0s 277us/sample - loss: 0.0204 - val_loss: 0.1668\n",
      "Epoch 476/600\n",
      "426/426 [==============================] - 0s 225us/sample - loss: 0.0215 - val_loss: 0.1677\n",
      "Epoch 477/600\n",
      "426/426 [==============================] - 0s 200us/sample - loss: 0.0205 - val_loss: 0.1924\n",
      "Epoch 478/600\n",
      "426/426 [==============================] - 0s 209us/sample - loss: 0.0270 - val_loss: 0.1712\n",
      "Epoch 479/600\n",
      "426/426 [==============================] - 0s 197us/sample - loss: 0.0205 - val_loss: 0.1714\n",
      "Epoch 480/600\n",
      "426/426 [==============================] - 0s 190us/sample - loss: 0.0227 - val_loss: 0.1947\n",
      "Epoch 481/600\n",
      "426/426 [==============================] - 0s 202us/sample - loss: 0.0208 - val_loss: 0.1647\n",
      "Epoch 482/600\n",
      "426/426 [==============================] - 0s 192us/sample - loss: 0.0227 - val_loss: 0.2156\n",
      "Epoch 483/600\n",
      "426/426 [==============================] - 0s 214us/sample - loss: 0.0225 - val_loss: 0.1583\n",
      "Epoch 484/600\n",
      "426/426 [==============================] - 0s 205us/sample - loss: 0.0207 - val_loss: 0.1863\n",
      "Epoch 485/600\n",
      "426/426 [==============================] - 0s 200us/sample - loss: 0.0201 - val_loss: 0.1624\n",
      "Epoch 486/600\n",
      "426/426 [==============================] - 0s 216us/sample - loss: 0.0199 - val_loss: 0.1917\n",
      "Epoch 487/600\n",
      "426/426 [==============================] - 0s 200us/sample - loss: 0.0204 - val_loss: 0.1617\n",
      "Epoch 488/600\n",
      "426/426 [==============================] - 0s 198us/sample - loss: 0.0220 - val_loss: 0.1869\n",
      "Epoch 489/600\n",
      "426/426 [==============================] - 0s 203us/sample - loss: 0.0199 - val_loss: 0.1677\n",
      "Epoch 490/600\n",
      "426/426 [==============================] - 0s 200us/sample - loss: 0.0201 - val_loss: 0.1768\n",
      "Epoch 491/600\n",
      "426/426 [==============================] - 0s 221us/sample - loss: 0.0224 - val_loss: 0.1871\n",
      "Epoch 492/600\n",
      "426/426 [==============================] - 0s 190us/sample - loss: 0.0211 - val_loss: 0.1778\n",
      "Epoch 493/600\n",
      "426/426 [==============================] - 0s 202us/sample - loss: 0.0196 - val_loss: 0.1896\n",
      "Epoch 494/600\n",
      "426/426 [==============================] - 0s 203us/sample - loss: 0.0200 - val_loss: 0.1667\n",
      "Epoch 495/600\n",
      "426/426 [==============================] - 0s 205us/sample - loss: 0.0243 - val_loss: 0.2181\n",
      "Epoch 496/600\n",
      "426/426 [==============================] - 0s 202us/sample - loss: 0.0220 - val_loss: 0.1585\n",
      "Epoch 497/600\n",
      "426/426 [==============================] - 0s 238us/sample - loss: 0.0213 - val_loss: 0.2190\n",
      "Epoch 498/600\n",
      "426/426 [==============================] - 0s 212us/sample - loss: 0.0214 - val_loss: 0.1797\n",
      "Epoch 499/600\n",
      "426/426 [==============================] - 0s 200us/sample - loss: 0.0186 - val_loss: 0.1944\n",
      "Epoch 500/600\n",
      "426/426 [==============================] - 0s 195us/sample - loss: 0.0183 - val_loss: 0.1682\n",
      "Epoch 501/600\n",
      "426/426 [==============================] - 0s 185us/sample - loss: 0.0211 - val_loss: 0.2198\n",
      "Epoch 502/600\n",
      "426/426 [==============================] - 0s 253us/sample - loss: 0.0229 - val_loss: 0.1719\n",
      "Epoch 503/600\n",
      "426/426 [==============================] - 0s 204us/sample - loss: 0.0205 - val_loss: 0.1926\n",
      "Epoch 504/600\n",
      "426/426 [==============================] - 0s 214us/sample - loss: 0.0188 - val_loss: 0.1790\n",
      "Epoch 505/600\n",
      "426/426 [==============================] - 0s 202us/sample - loss: 0.0198 - val_loss: 0.1801\n",
      "Epoch 506/600\n",
      "426/426 [==============================] - 0s 194us/sample - loss: 0.0188 - val_loss: 0.1779\n",
      "Epoch 507/600\n",
      "426/426 [==============================] - 0s 230us/sample - loss: 0.0198 - val_loss: 0.1751\n",
      "Epoch 508/600\n",
      "426/426 [==============================] - 0s 192us/sample - loss: 0.0218 - val_loss: 0.2067\n",
      "Epoch 509/600\n",
      "426/426 [==============================] - 0s 196us/sample - loss: 0.0203 - val_loss: 0.1682\n",
      "Epoch 510/600\n",
      "426/426 [==============================] - 0s 203us/sample - loss: 0.0214 - val_loss: 0.1925\n",
      "Epoch 511/600\n",
      "426/426 [==============================] - 0s 197us/sample - loss: 0.0196 - val_loss: 0.1772\n",
      "Epoch 512/600\n",
      "426/426 [==============================] - 0s 195us/sample - loss: 0.0188 - val_loss: 0.2004\n",
      "Epoch 513/600\n",
      "426/426 [==============================] - 0s 200us/sample - loss: 0.0192 - val_loss: 0.1663\n",
      "Epoch 514/600\n",
      "426/426 [==============================] - 0s 188us/sample - loss: 0.0213 - val_loss: 0.2083\n",
      "Epoch 515/600\n",
      "426/426 [==============================] - 0s 197us/sample - loss: 0.0218 - val_loss: 0.1945\n",
      "Epoch 516/600\n",
      "426/426 [==============================] - 0s 218us/sample - loss: 0.0211 - val_loss: 0.1740\n",
      "Epoch 517/600\n",
      "426/426 [==============================] - 0s 197us/sample - loss: 0.0223 - val_loss: 0.2015\n",
      "Epoch 518/600\n",
      "426/426 [==============================] - 0s 224us/sample - loss: 0.0187 - val_loss: 0.1777\n",
      "Epoch 519/600\n",
      "426/426 [==============================] - 0s 204us/sample - loss: 0.0187 - val_loss: 0.1886\n",
      "Epoch 520/600\n",
      "426/426 [==============================] - 0s 214us/sample - loss: 0.0181 - val_loss: 0.1776\n",
      "Epoch 521/600\n",
      "426/426 [==============================] - 0s 203us/sample - loss: 0.0239 - val_loss: 0.1951\n",
      "Epoch 522/600\n",
      "426/426 [==============================] - 0s 208us/sample - loss: 0.0187 - val_loss: 0.1824\n",
      "Epoch 523/600\n",
      "426/426 [==============================] - 0s 204us/sample - loss: 0.0181 - val_loss: 0.2356\n",
      "Epoch 524/600\n",
      "426/426 [==============================] - 0s 195us/sample - loss: 0.0209 - val_loss: 0.1664\n",
      "Epoch 525/600\n",
      "426/426 [==============================] - 0s 197us/sample - loss: 0.0216 - val_loss: 0.2141\n",
      "Epoch 526/600\n",
      "426/426 [==============================] - 0s 228us/sample - loss: 0.0204 - val_loss: 0.1820\n",
      "Epoch 527/600\n",
      "426/426 [==============================] - 0s 190us/sample - loss: 0.0176 - val_loss: 0.2002\n",
      "Epoch 528/600\n",
      "426/426 [==============================] - 0s 204us/sample - loss: 0.0180 - val_loss: 0.1732\n",
      "Epoch 529/600\n",
      "426/426 [==============================] - 0s 218us/sample - loss: 0.0280 - val_loss: 0.2483\n",
      "Epoch 530/600\n",
      "426/426 [==============================] - 0s 207us/sample - loss: 0.0275 - val_loss: 0.1684\n",
      "Epoch 531/600\n",
      "426/426 [==============================] - 0s 201us/sample - loss: 0.0218 - val_loss: 0.2283\n",
      "Epoch 532/600\n",
      "426/426 [==============================] - 0s 224us/sample - loss: 0.0210 - val_loss: 0.1952\n",
      "Epoch 533/600\n",
      "426/426 [==============================] - 0s 204us/sample - loss: 0.0275 - val_loss: 0.2137\n",
      "Epoch 534/600\n",
      "426/426 [==============================] - 0s 192us/sample - loss: 0.0487 - val_loss: 0.1692\n",
      "Epoch 535/600\n",
      "426/426 [==============================] - 0s 221us/sample - loss: 0.0382 - val_loss: 0.2872\n",
      "Epoch 536/600\n",
      "426/426 [==============================] - 0s 195us/sample - loss: 0.0330 - val_loss: 0.1581\n",
      "Epoch 537/600\n",
      "426/426 [==============================] - 0s 192us/sample - loss: 0.0168 - val_loss: 0.2221\n",
      "Epoch 538/600\n",
      "426/426 [==============================] - 0s 207us/sample - loss: 0.0226 - val_loss: 0.1726\n",
      "Epoch 539/600\n",
      "426/426 [==============================] - 0s 200us/sample - loss: 0.0188 - val_loss: 0.1847\n",
      "Epoch 540/600\n",
      "426/426 [==============================] - 0s 195us/sample - loss: 0.0177 - val_loss: 0.1952\n",
      "Epoch 541/600\n",
      "426/426 [==============================] - 0s 207us/sample - loss: 0.0183 - val_loss: 0.1856\n",
      "Epoch 542/600\n",
      "426/426 [==============================] - 0s 232us/sample - loss: 0.0186 - val_loss: 0.1927\n",
      "Epoch 543/600\n",
      "426/426 [==============================] - 0s 202us/sample - loss: 0.0175 - val_loss: 0.1883\n",
      "Epoch 544/600\n",
      "426/426 [==============================] - 0s 223us/sample - loss: 0.0170 - val_loss: 0.2004\n",
      "Epoch 545/600\n",
      "426/426 [==============================] - 0s 192us/sample - loss: 0.0178 - val_loss: 0.1949\n",
      "Epoch 546/600\n",
      "426/426 [==============================] - 0s 200us/sample - loss: 0.0183 - val_loss: 0.1997\n",
      "Epoch 547/600\n",
      "426/426 [==============================] - 0s 193us/sample - loss: 0.0182 - val_loss: 0.1768\n",
      "Epoch 548/600\n",
      "426/426 [==============================] - 0s 193us/sample - loss: 0.0203 - val_loss: 0.2177\n",
      "Epoch 549/600\n",
      "426/426 [==============================] - 0s 202us/sample - loss: 0.0210 - val_loss: 0.1733\n",
      "Epoch 550/600\n",
      "426/426 [==============================] - 0s 192us/sample - loss: 0.0208 - val_loss: 0.1857\n",
      "Epoch 551/600\n",
      "426/426 [==============================] - 0s 193us/sample - loss: 0.0233 - val_loss: 0.1821\n",
      "Epoch 552/600\n",
      "426/426 [==============================] - 0s 200us/sample - loss: 0.0209 - val_loss: 0.2182\n",
      "Epoch 553/600\n",
      "426/426 [==============================] - 0s 193us/sample - loss: 0.0177 - val_loss: 0.1919\n",
      "Epoch 554/600\n",
      "426/426 [==============================] - 0s 215us/sample - loss: 0.0168 - val_loss: 0.1919\n",
      "Epoch 555/600\n",
      "426/426 [==============================] - 0s 228us/sample - loss: 0.0168 - val_loss: 0.1950\n",
      "Epoch 556/600\n",
      "426/426 [==============================] - 0s 195us/sample - loss: 0.0174 - val_loss: 0.1854\n",
      "Epoch 557/600\n",
      "426/426 [==============================] - 0s 198us/sample - loss: 0.0183 - val_loss: 0.2115\n",
      "Epoch 558/600\n",
      "426/426 [==============================] - 0s 219us/sample - loss: 0.0170 - val_loss: 0.1809\n",
      "Epoch 559/600\n",
      "426/426 [==============================] - 0s 190us/sample - loss: 0.0231 - val_loss: 0.2198\n",
      "Epoch 560/600\n",
      "426/426 [==============================] - 0s 206us/sample - loss: 0.0156 - val_loss: 0.1767\n",
      "Epoch 561/600\n",
      "426/426 [==============================] - 0s 225us/sample - loss: 0.0164 - val_loss: 0.2243\n",
      "Epoch 562/600\n",
      "426/426 [==============================] - 0s 202us/sample - loss: 0.0182 - val_loss: 0.1783\n",
      "Epoch 563/600\n",
      "426/426 [==============================] - 0s 200us/sample - loss: 0.0186 - val_loss: 0.2038\n",
      "Epoch 564/600\n",
      "426/426 [==============================] - 0s 210us/sample - loss: 0.0169 - val_loss: 0.2015\n",
      "Epoch 565/600\n",
      "426/426 [==============================] - 0s 192us/sample - loss: 0.0187 - val_loss: 0.2039\n",
      "Epoch 566/600\n",
      "426/426 [==============================] - 0s 195us/sample - loss: 0.0163 - val_loss: 0.1930\n",
      "Epoch 567/600\n",
      "426/426 [==============================] - 0s 205us/sample - loss: 0.0179 - val_loss: 0.2139\n",
      "Epoch 568/600\n",
      "426/426 [==============================] - 0s 216us/sample - loss: 0.0161 - val_loss: 0.1984\n",
      "Epoch 569/600\n",
      "426/426 [==============================] - 0s 200us/sample - loss: 0.0160 - val_loss: 0.1996\n",
      "Epoch 570/600\n",
      "426/426 [==============================] - 0s 221us/sample - loss: 0.0158 - val_loss: 0.2012\n",
      "Epoch 571/600\n",
      "426/426 [==============================] - 0s 204us/sample - loss: 0.0166 - val_loss: 0.1959\n",
      "Epoch 572/600\n",
      "426/426 [==============================] - 0s 197us/sample - loss: 0.0161 - val_loss: 0.2000\n",
      "Epoch 573/600\n",
      "426/426 [==============================] - 0s 218us/sample - loss: 0.0154 - val_loss: 0.2211\n",
      "Epoch 574/600\n",
      "426/426 [==============================] - 0s 197us/sample - loss: 0.0173 - val_loss: 0.1921\n",
      "Epoch 575/600\n",
      "426/426 [==============================] - 0s 200us/sample - loss: 0.0169 - val_loss: 0.1984\n",
      "Epoch 576/600\n",
      "426/426 [==============================] - 0s 207us/sample - loss: 0.0160 - val_loss: 0.2288\n",
      "Epoch 577/600\n",
      "426/426 [==============================] - 0s 251us/sample - loss: 0.0161 - val_loss: 0.1920\n",
      "Epoch 578/600\n",
      "426/426 [==============================] - 0s 200us/sample - loss: 0.0179 - val_loss: 0.1949\n",
      "Epoch 579/600\n",
      "426/426 [==============================] - 0s 202us/sample - loss: 0.0174 - val_loss: 0.2195\n",
      "Epoch 580/600\n",
      "426/426 [==============================] - 0s 193us/sample - loss: 0.0156 - val_loss: 0.1953\n",
      "Epoch 581/600\n",
      "426/426 [==============================] - 0s 280us/sample - loss: 0.0178 - val_loss: 0.2117\n",
      "Epoch 582/600\n",
      "426/426 [==============================] - 0s 191us/sample - loss: 0.0155 - val_loss: 0.1975\n",
      "Epoch 583/600\n",
      "426/426 [==============================] - 0s 204us/sample - loss: 0.0150 - val_loss: 0.2423\n",
      "Epoch 584/600\n",
      "426/426 [==============================] - 0s 202us/sample - loss: 0.0176 - val_loss: 0.2120\n",
      "Epoch 585/600\n",
      "426/426 [==============================] - 0s 190us/sample - loss: 0.0183 - val_loss: 0.2174\n",
      "Epoch 586/600\n",
      "426/426 [==============================] - 0s 195us/sample - loss: 0.0151 - val_loss: 0.1983\n",
      "Epoch 587/600\n",
      "426/426 [==============================] - 0s 207us/sample - loss: 0.0159 - val_loss: 0.2053\n",
      "Epoch 588/600\n",
      "426/426 [==============================] - 0s 195us/sample - loss: 0.0161 - val_loss: 0.1968\n",
      "Epoch 589/600\n",
      "426/426 [==============================] - 0s 195us/sample - loss: 0.0154 - val_loss: 0.2034\n",
      "Epoch 590/600\n",
      "426/426 [==============================] - 0s 203us/sample - loss: 0.0140 - val_loss: 0.2092\n",
      "Epoch 591/600\n",
      "426/426 [==============================] - 0s 190us/sample - loss: 0.0157 - val_loss: 0.2012\n",
      "Epoch 592/600\n",
      "426/426 [==============================] - 0s 193us/sample - loss: 0.0147 - val_loss: 0.2163\n",
      "Epoch 593/600\n",
      "426/426 [==============================] - 0s 200us/sample - loss: 0.0148 - val_loss: 0.2215\n",
      "Epoch 594/600\n",
      "426/426 [==============================] - 0s 190us/sample - loss: 0.0147 - val_loss: 0.2170\n",
      "Epoch 595/600\n",
      "426/426 [==============================] - 0s 190us/sample - loss: 0.0146 - val_loss: 0.1969\n",
      "Epoch 596/600\n",
      "426/426 [==============================] - 0s 202us/sample - loss: 0.0235 - val_loss: 0.2624\n",
      "Epoch 597/600\n",
      "426/426 [==============================] - 0s 190us/sample - loss: 0.0220 - val_loss: 0.1814\n",
      "Epoch 598/600\n",
      "426/426 [==============================] - 0s 200us/sample - loss: 0.0173 - val_loss: 0.2450\n",
      "Epoch 599/600\n",
      "426/426 [==============================] - 0s 214us/sample - loss: 0.0169 - val_loss: 0.1982\n",
      "Epoch 600/600\n",
      "426/426 [==============================] - 0s 205us/sample - loss: 0.0139 - val_loss: 0.2124\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f1e863a148>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          epochs=600,\n",
    "          validation_data=(X_test, y_test)\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the losses, is clearly an overfitting case:\n",
    "\n",
    "in the begining both validation and training loss are decreasing, that's good.\n",
    "\n",
    "However at certain time the validation loss diverges, that's an indicator that we trainend with **too many EPOCHS**, the val_loss get worst and worst after those many epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1f1e9c03108>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = pd.DataFrame(model.history.history)\n",
    "losses.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're going to see if we can use **early stopping**:\n",
    "\n",
    "Based on validation loss, stop the training before it gets out of hand.\n",
    "\n",
    "Creating the model again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(30,'relu')) # 1st layer (INPUT)\n",
    "model.add(Dense(15,'relu')) # 2nd layer\n",
    "\n",
    "#Last layer, one neuron and SIGMOID (BINARY CLASSIFICATION)\n",
    "model.add(Dense(1,'sigmoid'))\n",
    "\n",
    "# For a binary classification problem\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callbacks for early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmin_delta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mbaseline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mrestore_best_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Stop training when a monitored quantity has stopped improving.\n",
       "\n",
       "Arguments:\n",
       "    monitor: Quantity to be monitored.\n",
       "    min_delta: Minimum change in the monitored quantity\n",
       "        to qualify as an improvement, i.e. an absolute\n",
       "        change of less than min_delta, will count as no\n",
       "        improvement.\n",
       "    patience: Number of epochs with no improvement\n",
       "        after which training will be stopped.\n",
       "    verbose: verbosity mode.\n",
       "    mode: One of `{\"auto\", \"min\", \"max\"}`. In `min` mode,\n",
       "        training will stop when the quantity\n",
       "        monitored has stopped decreasing; in `max`\n",
       "        mode it will stop when the quantity\n",
       "        monitored has stopped increasing; in `auto`\n",
       "        mode, the direction is automatically inferred\n",
       "        from the name of the monitored quantity.\n",
       "    baseline: Baseline value for the monitored quantity.\n",
       "        Training will stop if the model doesn't show improvement over the\n",
       "        baseline.\n",
       "    restore_best_weights: Whether to restore model weights from\n",
       "        the epoch with the best value of the monitored quantity.\n",
       "        If False, the model weights obtained at the last step of\n",
       "        training are used.\n",
       "\n",
       "Example:\n",
       "\n",
       "```python\n",
       "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
       "# This callback will stop the training when there is no improvement in\n",
       "# the validation loss for three consecutive epochs.\n",
       "model.fit(data, labels, epochs=100, callbacks=[callback],\n",
       "    validation_data=(val_data, val_labels))\n",
       "```\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\fernando\\appdata\\roaming\\python\\python37\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EarlyStopping?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mode**: for accuracy we want to MAX that, for loss we want to MIN that.\n",
    "\n",
    "Verbose to have a report back\n",
    "\n",
    "patience, we wait 25 epochs even after detect one stopping point, because of noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min',patience=25, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 426 samples, validate on 143 samples\n",
      "Epoch 1/600\n",
      "426/426 [==============================] - 4s 8ms/sample - loss: 0.6937 - val_loss: 0.6704\n",
      "Epoch 2/600\n",
      "426/426 [==============================] - 0s 462us/sample - loss: 0.6537 - val_loss: 0.6375\n",
      "Epoch 3/600\n",
      "426/426 [==============================] - 0s 404us/sample - loss: 0.6179 - val_loss: 0.5991\n",
      "Epoch 4/600\n",
      "426/426 [==============================] - 0s 488us/sample - loss: 0.5744 - val_loss: 0.5510\n",
      "Epoch 5/600\n",
      "426/426 [==============================] - 0s 408us/sample - loss: 0.5251 - val_loss: 0.4979\n",
      "Epoch 6/600\n",
      "426/426 [==============================] - 0s 388us/sample - loss: 0.4698 - val_loss: 0.4381\n",
      "Epoch 7/600\n",
      "426/426 [==============================] - 0s 470us/sample - loss: 0.4143 - val_loss: 0.3825\n",
      "Epoch 8/600\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.365 - 0s 568us/sample - loss: 0.3629 - val_loss: 0.3310\n",
      "Epoch 9/600\n",
      "426/426 [==============================] - 0s 500us/sample - loss: 0.3210 - val_loss: 0.2903\n",
      "Epoch 10/600\n",
      "426/426 [==============================] - 0s 477us/sample - loss: 0.2877 - val_loss: 0.2564\n",
      "Epoch 11/600\n",
      "426/426 [==============================] - 0s 418us/sample - loss: 0.2590 - val_loss: 0.2328\n",
      "Epoch 12/600\n",
      "426/426 [==============================] - 0s 395us/sample - loss: 0.2348 - val_loss: 0.2062\n",
      "Epoch 13/600\n",
      "426/426 [==============================] - 0s 448us/sample - loss: 0.2169 - val_loss: 0.1879\n",
      "Epoch 14/600\n",
      "426/426 [==============================] - 0s 470us/sample - loss: 0.1982 - val_loss: 0.1820\n",
      "Epoch 15/600\n",
      "426/426 [==============================] - 0s 383us/sample - loss: 0.1918 - val_loss: 0.1619\n",
      "Epoch 16/600\n",
      "426/426 [==============================] - 0s 394us/sample - loss: 0.1729 - val_loss: 0.1573\n",
      "Epoch 17/600\n",
      "426/426 [==============================] - 0s 401us/sample - loss: 0.1715 - val_loss: 0.1467\n",
      "Epoch 18/600\n",
      "426/426 [==============================] - 0s 404us/sample - loss: 0.1545 - val_loss: 0.1439\n",
      "Epoch 19/600\n",
      "426/426 [==============================] - 0s 411us/sample - loss: 0.1460 - val_loss: 0.1346\n",
      "Epoch 20/600\n",
      "426/426 [==============================] - 0s 378us/sample - loss: 0.1398 - val_loss: 0.1305\n",
      "Epoch 21/600\n",
      "426/426 [==============================] - 0s 343us/sample - loss: 0.1334 - val_loss: 0.1272\n",
      "Epoch 22/600\n",
      "426/426 [==============================] - 0s 329us/sample - loss: 0.1289 - val_loss: 0.1234\n",
      "Epoch 23/600\n",
      "426/426 [==============================] - 0s 312us/sample - loss: 0.1203 - val_loss: 0.1207\n",
      "Epoch 24/600\n",
      "426/426 [==============================] - 0s 310us/sample - loss: 0.1149 - val_loss: 0.1213\n",
      "Epoch 25/600\n",
      "426/426 [==============================] - 0s 333us/sample - loss: 0.1103 - val_loss: 0.1151\n",
      "Epoch 26/600\n",
      "426/426 [==============================] - 0s 378us/sample - loss: 0.1055 - val_loss: 0.1154\n",
      "Epoch 27/600\n",
      "426/426 [==============================] - 0s 347us/sample - loss: 0.1015 - val_loss: 0.1105\n",
      "Epoch 28/600\n",
      "426/426 [==============================] - 0s 312us/sample - loss: 0.0984 - val_loss: 0.1150\n",
      "Epoch 29/600\n",
      "426/426 [==============================] - 0s 321us/sample - loss: 0.0942 - val_loss: 0.1075\n",
      "Epoch 30/600\n",
      "426/426 [==============================] - 0s 349us/sample - loss: 0.0939 - val_loss: 0.1057\n",
      "Epoch 31/600\n",
      "426/426 [==============================] - 0s 322us/sample - loss: 0.0895 - val_loss: 0.1073\n",
      "Epoch 32/600\n",
      "426/426 [==============================] - 0s 341us/sample - loss: 0.0918 - val_loss: 0.1033\n",
      "Epoch 33/600\n",
      "426/426 [==============================] - 0s 339us/sample - loss: 0.0854 - val_loss: 0.1053\n",
      "Epoch 34/600\n",
      "426/426 [==============================] - 0s 345us/sample - loss: 0.0894 - val_loss: 0.1049\n",
      "Epoch 35/600\n",
      "426/426 [==============================] - 0s 322us/sample - loss: 0.0848 - val_loss: 0.1084\n",
      "Epoch 36/600\n",
      "426/426 [==============================] - 0s 337us/sample - loss: 0.0788 - val_loss: 0.1067\n",
      "Epoch 37/600\n",
      "426/426 [==============================] - 0s 319us/sample - loss: 0.0789 - val_loss: 0.1041\n",
      "Epoch 38/600\n",
      "426/426 [==============================] - 0s 308us/sample - loss: 0.0759 - val_loss: 0.1099\n",
      "Epoch 39/600\n",
      "426/426 [==============================] - 0s 343us/sample - loss: 0.0741 - val_loss: 0.1027\n",
      "Epoch 40/600\n",
      "426/426 [==============================] - 0s 329us/sample - loss: 0.0733 - val_loss: 0.1058\n",
      "Epoch 41/600\n",
      "426/426 [==============================] - 0s 310us/sample - loss: 0.0716 - val_loss: 0.1063\n",
      "Epoch 42/600\n",
      "426/426 [==============================] - 0s 319us/sample - loss: 0.0702 - val_loss: 0.1042\n",
      "Epoch 43/600\n",
      "426/426 [==============================] - 0s 326us/sample - loss: 0.0684 - val_loss: 0.1055\n",
      "Epoch 44/600\n",
      "426/426 [==============================] - 0s 315us/sample - loss: 0.0693 - val_loss: 0.1081\n",
      "Epoch 45/600\n",
      "426/426 [==============================] - 0s 329us/sample - loss: 0.0714 - val_loss: 0.1087\n",
      "Epoch 46/600\n",
      "426/426 [==============================] - 0s 329us/sample - loss: 0.0665 - val_loss: 0.1038\n",
      "Epoch 47/600\n",
      "426/426 [==============================] - 0s 317us/sample - loss: 0.0668 - val_loss: 0.1074\n",
      "Epoch 48/600\n",
      "426/426 [==============================] - 0s 310us/sample - loss: 0.0655 - val_loss: 0.1061\n",
      "Epoch 49/600\n",
      "426/426 [==============================] - 0s 305us/sample - loss: 0.0651 - val_loss: 0.1026\n",
      "Epoch 50/600\n",
      "426/426 [==============================] - 0s 299us/sample - loss: 0.0637 - val_loss: 0.1053\n",
      "Epoch 51/600\n",
      "426/426 [==============================] - 0s 315us/sample - loss: 0.0622 - val_loss: 0.1068\n",
      "Epoch 52/600\n",
      "426/426 [==============================] - 0s 322us/sample - loss: 0.0617 - val_loss: 0.1036\n",
      "Epoch 53/600\n",
      "426/426 [==============================] - 0s 354us/sample - loss: 0.0606 - val_loss: 0.1084\n",
      "Epoch 54/600\n",
      "426/426 [==============================] - 0s 331us/sample - loss: 0.0612 - val_loss: 0.1046\n",
      "Epoch 55/600\n",
      "426/426 [==============================] - 0s 315us/sample - loss: 0.0612 - val_loss: 0.1029\n",
      "Epoch 56/600\n",
      "426/426 [==============================] - 0s 319us/sample - loss: 0.0611 - val_loss: 0.1043\n",
      "Epoch 57/600\n",
      "426/426 [==============================] - 0s 329us/sample - loss: 0.0584 - val_loss: 0.1093\n",
      "Epoch 58/600\n",
      "426/426 [==============================] - 0s 324us/sample - loss: 0.0584 - val_loss: 0.1066\n",
      "Epoch 59/600\n",
      "426/426 [==============================] - 0s 316us/sample - loss: 0.0591 - val_loss: 0.1101\n",
      "Epoch 60/600\n",
      "426/426 [==============================] - 0s 338us/sample - loss: 0.0581 - val_loss: 0.1070\n",
      "Epoch 61/600\n",
      "426/426 [==============================] - 0s 329us/sample - loss: 0.0575 - val_loss: 0.1107\n",
      "Epoch 62/600\n",
      "426/426 [==============================] - 0s 306us/sample - loss: 0.0564 - val_loss: 0.1130\n",
      "Epoch 63/600\n",
      "426/426 [==============================] - 0s 329us/sample - loss: 0.0554 - val_loss: 0.1065\n",
      "Epoch 64/600\n",
      "426/426 [==============================] - 0s 317us/sample - loss: 0.0559 - val_loss: 0.1094\n",
      "Epoch 65/600\n",
      "426/426 [==============================] - 0s 315us/sample - loss: 0.0568 - val_loss: 0.1124\n",
      "Epoch 66/600\n",
      "426/426 [==============================] - 0s 306us/sample - loss: 0.0543 - val_loss: 0.1090\n",
      "Epoch 67/600\n",
      "426/426 [==============================] - 0s 331us/sample - loss: 0.0549 - val_loss: 0.1144\n",
      "Epoch 68/600\n",
      "426/426 [==============================] - 0s 312us/sample - loss: 0.0547 - val_loss: 0.1132\n",
      "Epoch 69/600\n",
      "426/426 [==============================] - 0s 317us/sample - loss: 0.0536 - val_loss: 0.1137\n",
      "Epoch 70/600\n",
      "426/426 [==============================] - 0s 308us/sample - loss: 0.0563 - val_loss: 0.1199\n",
      "Epoch 71/600\n",
      "426/426 [==============================] - 0s 308us/sample - loss: 0.0543 - val_loss: 0.1148\n",
      "Epoch 72/600\n",
      "426/426 [==============================] - 0s 303us/sample - loss: 0.0529 - val_loss: 0.1102\n",
      "Epoch 73/600\n",
      "426/426 [==============================] - 0s 304us/sample - loss: 0.0584 - val_loss: 0.1306\n",
      "Epoch 74/600\n",
      "426/426 [==============================] - 0s 315us/sample - loss: 0.0561 - val_loss: 0.1107\n",
      "Epoch 00074: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f1e9dff488>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          epochs=600,\n",
    "          validation_data=(X_test, y_test),\n",
    "          callbacks=[early_stop]\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The advantage of the eraly stop is that we can choose any large trivial epoch number and the early stopp tells the model when to stop :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1f1ea39b1c8>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_loss = pd.DataFrame(model.history.history)\n",
    "model_loss.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third thing to do for trying to prevent overfitting:\n",
    "\n",
    "## Dropout Layers\n",
    "\n",
    "**Dropout Layers**: Turn off percentage of neurons randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(30,'relu')) # 1st layer (INPUT)\n",
    "#DROPOUT: rate - probability for turn off neuron, 50%\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "model.add(Dense(15,'relu')) # 2nd layer\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "#Last layer, one neuron and SIGMOID (BINARY CLASSIFICATION)\n",
    "model.add(Dense(1,'sigmoid'))\n",
    "\n",
    "# For a binary classification problem\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min',patience=25, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 426 samples, validate on 143 samples\n",
      "Epoch 1/600\n",
      "426/426 [==============================] - 3s 7ms/sample - loss: 0.6951 - val_loss: 0.6737\n",
      "Epoch 2/600\n",
      "426/426 [==============================] - 0s 378us/sample - loss: 0.6843 - val_loss: 0.6579\n",
      "Epoch 3/600\n",
      "426/426 [==============================] - 0s 390us/sample - loss: 0.6520 - val_loss: 0.6420\n",
      "Epoch 4/600\n",
      "426/426 [==============================] - 0s 385us/sample - loss: 0.6542 - val_loss: 0.6273\n",
      "Epoch 5/600\n",
      "426/426 [==============================] - 0s 390us/sample - loss: 0.6406 - val_loss: 0.6075\n",
      "Epoch 6/600\n",
      "426/426 [==============================] - 0s 441us/sample - loss: 0.6145 - val_loss: 0.5796\n",
      "Epoch 7/600\n",
      "426/426 [==============================] - 0s 453us/sample - loss: 0.6130 - val_loss: 0.5533\n",
      "Epoch 8/600\n",
      "426/426 [==============================] - 0s 354us/sample - loss: 0.5964 - val_loss: 0.5366\n",
      "Epoch 9/600\n",
      "426/426 [==============================] - 0s 354us/sample - loss: 0.5459 - val_loss: 0.5040\n",
      "Epoch 10/600\n",
      "426/426 [==============================] - 0s 364us/sample - loss: 0.5319 - val_loss: 0.4685\n",
      "Epoch 11/600\n",
      "426/426 [==============================] - 0s 333us/sample - loss: 0.5275 - val_loss: 0.4430\n",
      "Epoch 12/600\n",
      "426/426 [==============================] - 0s 343us/sample - loss: 0.5092 - val_loss: 0.4198\n",
      "Epoch 13/600\n",
      "426/426 [==============================] - 0s 359us/sample - loss: 0.4621 - val_loss: 0.3939\n",
      "Epoch 14/600\n",
      "426/426 [==============================] - 0s 333us/sample - loss: 0.4559 - val_loss: 0.3675\n",
      "Epoch 15/600\n",
      "426/426 [==============================] - 0s 340us/sample - loss: 0.4463 - val_loss: 0.3460\n",
      "Epoch 16/600\n",
      "426/426 [==============================] - 0s 333us/sample - loss: 0.4277 - val_loss: 0.3181\n",
      "Epoch 17/600\n",
      "426/426 [==============================] - 0s 319us/sample - loss: 0.3905 - val_loss: 0.2958\n",
      "Epoch 18/600\n",
      "426/426 [==============================] - 0s 338us/sample - loss: 0.3635 - val_loss: 0.2834\n",
      "Epoch 19/600\n",
      "426/426 [==============================] - 0s 333us/sample - loss: 0.3576 - val_loss: 0.2639\n",
      "Epoch 20/600\n",
      "426/426 [==============================] - 0s 362us/sample - loss: 0.3406 - val_loss: 0.2448\n",
      "Epoch 21/600\n",
      "426/426 [==============================] - 0s 338us/sample - loss: 0.3832 - val_loss: 0.2373\n",
      "Epoch 22/600\n",
      "426/426 [==============================] - 0s 326us/sample - loss: 0.3218 - val_loss: 0.2364\n",
      "Epoch 23/600\n",
      "426/426 [==============================] - 0s 322us/sample - loss: 0.3390 - val_loss: 0.2243\n",
      "Epoch 24/600\n",
      "426/426 [==============================] - 0s 334us/sample - loss: 0.3091 - val_loss: 0.2155\n",
      "Epoch 25/600\n",
      "426/426 [==============================] - 0s 357us/sample - loss: 0.3203 - val_loss: 0.2033\n",
      "Epoch 26/600\n",
      "426/426 [==============================] - 0s 380us/sample - loss: 0.2920 - val_loss: 0.2099\n",
      "Epoch 27/600\n",
      "426/426 [==============================] - 0s 326us/sample - loss: 0.2829 - val_loss: 0.1889\n",
      "Epoch 28/600\n",
      "426/426 [==============================] - 0s 347us/sample - loss: 0.2684 - val_loss: 0.1745\n",
      "Epoch 29/600\n",
      "426/426 [==============================] - 0s 355us/sample - loss: 0.2814 - val_loss: 0.1750\n",
      "Epoch 30/600\n",
      "426/426 [==============================] - 0s 373us/sample - loss: 0.3013 - val_loss: 0.1690\n",
      "Epoch 31/600\n",
      "426/426 [==============================] - 0s 345us/sample - loss: 0.2576 - val_loss: 0.1702\n",
      "Epoch 32/600\n",
      "426/426 [==============================] - 0s 336us/sample - loss: 0.2367 - val_loss: 0.1601\n",
      "Epoch 33/600\n",
      "426/426 [==============================] - 0s 326us/sample - loss: 0.2365 - val_loss: 0.1526\n",
      "Epoch 34/600\n",
      "426/426 [==============================] - 0s 338us/sample - loss: 0.2222 - val_loss: 0.1534\n",
      "Epoch 35/600\n",
      "426/426 [==============================] - 0s 331us/sample - loss: 0.2637 - val_loss: 0.1567\n",
      "Epoch 36/600\n",
      "426/426 [==============================] - 0s 326us/sample - loss: 0.2567 - val_loss: 0.1539\n",
      "Epoch 37/600\n",
      "426/426 [==============================] - 0s 350us/sample - loss: 0.2284 - val_loss: 0.1493\n",
      "Epoch 38/600\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.246 - 0s 387us/sample - loss: 0.2238 - val_loss: 0.1499\n",
      "Epoch 39/600\n",
      "426/426 [==============================] - 0s 347us/sample - loss: 0.2199 - val_loss: 0.1434\n",
      "Epoch 40/600\n",
      "426/426 [==============================] - 0s 336us/sample - loss: 0.1975 - val_loss: 0.1421\n",
      "Epoch 41/600\n",
      "426/426 [==============================] - 0s 338us/sample - loss: 0.2222 - val_loss: 0.1315\n",
      "Epoch 42/600\n",
      "426/426 [==============================] - 0s 369us/sample - loss: 0.2040 - val_loss: 0.1319\n",
      "Epoch 43/600\n",
      "426/426 [==============================] - 0s 354us/sample - loss: 0.2144 - val_loss: 0.1341\n",
      "Epoch 44/600\n",
      "426/426 [==============================] - 0s 336us/sample - loss: 0.2005 - val_loss: 0.1314\n",
      "Epoch 45/600\n",
      "426/426 [==============================] - 0s 319us/sample - loss: 0.1993 - val_loss: 0.1279\n",
      "Epoch 46/600\n",
      "426/426 [==============================] - 0s 352us/sample - loss: 0.2052 - val_loss: 0.1231\n",
      "Epoch 47/600\n",
      "426/426 [==============================] - 0s 446us/sample - loss: 0.1822 - val_loss: 0.1255\n",
      "Epoch 48/600\n",
      "426/426 [==============================] - 0s 331us/sample - loss: 0.1690 - val_loss: 0.1296\n",
      "Epoch 49/600\n",
      "426/426 [==============================] - 0s 371us/sample - loss: 0.1981 - val_loss: 0.1181\n",
      "Epoch 50/600\n",
      "426/426 [==============================] - 0s 359us/sample - loss: 0.2065 - val_loss: 0.1155\n",
      "Epoch 51/600\n",
      "426/426 [==============================] - 0s 333us/sample - loss: 0.1911 - val_loss: 0.1197\n",
      "Epoch 52/600\n",
      "426/426 [==============================] - 0s 322us/sample - loss: 0.2048 - val_loss: 0.1179\n",
      "Epoch 53/600\n",
      "426/426 [==============================] - 0s 315us/sample - loss: 0.1702 - val_loss: 0.1191\n",
      "Epoch 54/600\n",
      "426/426 [==============================] - 0s 338us/sample - loss: 0.1680 - val_loss: 0.1115\n",
      "Epoch 55/600\n",
      "426/426 [==============================] - 0s 338us/sample - loss: 0.1703 - val_loss: 0.1137\n",
      "Epoch 56/600\n",
      "426/426 [==============================] - 0s 350us/sample - loss: 0.1561 - val_loss: 0.1103\n",
      "Epoch 57/600\n",
      "426/426 [==============================] - 0s 336us/sample - loss: 0.1575 - val_loss: 0.1131\n",
      "Epoch 58/600\n",
      "426/426 [==============================] - 0s 309us/sample - loss: 0.1457 - val_loss: 0.1124\n",
      "Epoch 59/600\n",
      "426/426 [==============================] - 0s 349us/sample - loss: 0.1695 - val_loss: 0.1060\n",
      "Epoch 60/600\n",
      "426/426 [==============================] - 0s 329us/sample - loss: 0.1766 - val_loss: 0.1299\n",
      "Epoch 61/600\n",
      "426/426 [==============================] - 0s 406us/sample - loss: 0.1755 - val_loss: 0.1106\n",
      "Epoch 62/600\n",
      "426/426 [==============================] - 0s 340us/sample - loss: 0.1449 - val_loss: 0.1031\n",
      "Epoch 63/600\n",
      "426/426 [==============================] - 0s 322us/sample - loss: 0.1416 - val_loss: 0.1045\n",
      "Epoch 64/600\n",
      "426/426 [==============================] - 0s 324us/sample - loss: 0.1491 - val_loss: 0.1024\n",
      "Epoch 65/600\n",
      "426/426 [==============================] - 0s 324us/sample - loss: 0.1529 - val_loss: 0.1174\n",
      "Epoch 66/600\n",
      "426/426 [==============================] - 0s 427us/sample - loss: 0.1669 - val_loss: 0.1088\n",
      "Epoch 67/600\n",
      "426/426 [==============================] - 0s 486us/sample - loss: 0.1529 - val_loss: 0.1026\n",
      "Epoch 68/600\n",
      "426/426 [==============================] - 0s 495us/sample - loss: 0.1244 - val_loss: 0.1003\n",
      "Epoch 69/600\n",
      "426/426 [==============================] - 0s 397us/sample - loss: 0.1271 - val_loss: 0.0971\n",
      "Epoch 70/600\n",
      "426/426 [==============================] - 0s 528us/sample - loss: 0.1412 - val_loss: 0.1029\n",
      "Epoch 71/600\n",
      "426/426 [==============================] - 0s 326us/sample - loss: 0.1493 - val_loss: 0.1000\n",
      "Epoch 72/600\n",
      "426/426 [==============================] - 0s 272us/sample - loss: 0.1414 - val_loss: 0.0982\n",
      "Epoch 73/600\n",
      "426/426 [==============================] - 0s 272us/sample - loss: 0.1484 - val_loss: 0.0963\n",
      "Epoch 74/600\n",
      "426/426 [==============================] - 0s 275us/sample - loss: 0.1663 - val_loss: 0.1166\n",
      "Epoch 75/600\n",
      "426/426 [==============================] - 0s 340us/sample - loss: 0.1574 - val_loss: 0.0980\n",
      "Epoch 76/600\n",
      "426/426 [==============================] - 0s 284us/sample - loss: 0.1304 - val_loss: 0.1086\n",
      "Epoch 77/600\n",
      "426/426 [==============================] - 0s 310us/sample - loss: 0.1446 - val_loss: 0.1002\n",
      "Epoch 78/600\n",
      "426/426 [==============================] - 0s 291us/sample - loss: 0.1280 - val_loss: 0.1026\n",
      "Epoch 79/600\n",
      "426/426 [==============================] - 0s 282us/sample - loss: 0.1263 - val_loss: 0.0996\n",
      "Epoch 80/600\n",
      "426/426 [==============================] - 0s 315us/sample - loss: 0.1310 - val_loss: 0.0973\n",
      "Epoch 81/600\n",
      "426/426 [==============================] - 0s 333us/sample - loss: 0.1401 - val_loss: 0.1033\n",
      "Epoch 82/600\n",
      "426/426 [==============================] - 0s 307us/sample - loss: 0.1327 - val_loss: 0.0997\n",
      "Epoch 83/600\n",
      "426/426 [==============================] - 0s 317us/sample - loss: 0.1373 - val_loss: 0.1011\n",
      "Epoch 84/600\n",
      "426/426 [==============================] - 0s 300us/sample - loss: 0.1330 - val_loss: 0.0983\n",
      "Epoch 85/600\n",
      "426/426 [==============================] - 0s 265us/sample - loss: 0.1469 - val_loss: 0.0979\n",
      "Epoch 86/600\n",
      "426/426 [==============================] - 0s 282us/sample - loss: 0.1337 - val_loss: 0.1050\n",
      "Epoch 87/600\n",
      "426/426 [==============================] - 0s 338us/sample - loss: 0.1206 - val_loss: 0.1017\n",
      "Epoch 88/600\n",
      "426/426 [==============================] - 0s 312us/sample - loss: 0.1186 - val_loss: 0.1039\n",
      "Epoch 89/600\n",
      "426/426 [==============================] - 0s 300us/sample - loss: 0.1319 - val_loss: 0.0969\n",
      "Epoch 90/600\n",
      "426/426 [==============================] - 0s 312us/sample - loss: 0.1451 - val_loss: 0.1067\n",
      "Epoch 91/600\n",
      "426/426 [==============================] - 0s 272us/sample - loss: 0.1341 - val_loss: 0.1053\n",
      "Epoch 92/600\n",
      "426/426 [==============================] - 0s 298us/sample - loss: 0.1124 - val_loss: 0.0991\n",
      "Epoch 93/600\n",
      "426/426 [==============================] - 0s 282us/sample - loss: 0.1093 - val_loss: 0.0998\n",
      "Epoch 94/600\n",
      "426/426 [==============================] - 0s 265us/sample - loss: 0.1152 - val_loss: 0.0971\n",
      "Epoch 95/600\n",
      "426/426 [==============================] - 0s 270us/sample - loss: 0.1357 - val_loss: 0.1015\n",
      "Epoch 96/600\n",
      "426/426 [==============================] - 0s 270us/sample - loss: 0.1110 - val_loss: 0.0943\n",
      "Epoch 97/600\n",
      "426/426 [==============================] - 0s 263us/sample - loss: 0.1089 - val_loss: 0.0968\n",
      "Epoch 98/600\n",
      "426/426 [==============================] - 0s 268us/sample - loss: 0.1067 - val_loss: 0.1142\n",
      "Epoch 99/600\n",
      "426/426 [==============================] - 0s 272us/sample - loss: 0.1363 - val_loss: 0.1055\n",
      "Epoch 100/600\n",
      "426/426 [==============================] - 0s 275us/sample - loss: 0.1186 - val_loss: 0.1009\n",
      "Epoch 101/600\n",
      "426/426 [==============================] - 0s 265us/sample - loss: 0.1106 - val_loss: 0.1069\n",
      "Epoch 102/600\n",
      "426/426 [==============================] - 0s 268us/sample - loss: 0.1102 - val_loss: 0.0936\n",
      "Epoch 103/600\n",
      "426/426 [==============================] - 0s 263us/sample - loss: 0.0969 - val_loss: 0.0896\n",
      "Epoch 104/600\n",
      "426/426 [==============================] - 0s 322us/sample - loss: 0.1151 - val_loss: 0.1020\n",
      "Epoch 105/600\n",
      "426/426 [==============================] - 0s 298us/sample - loss: 0.1154 - val_loss: 0.0981\n",
      "Epoch 106/600\n",
      "426/426 [==============================] - 0s 326us/sample - loss: 0.0979 - val_loss: 0.0986\n",
      "Epoch 107/600\n",
      "426/426 [==============================] - 0s 336us/sample - loss: 0.1139 - val_loss: 0.0934\n",
      "Epoch 108/600\n",
      "426/426 [==============================] - 0s 282us/sample - loss: 0.1084 - val_loss: 0.0945\n",
      "Epoch 109/600\n",
      "426/426 [==============================] - 0s 301us/sample - loss: 0.1211 - val_loss: 0.0979\n",
      "Epoch 110/600\n",
      "426/426 [==============================] - 0s 277us/sample - loss: 0.0883 - val_loss: 0.0935\n",
      "Epoch 111/600\n",
      "426/426 [==============================] - 0s 305us/sample - loss: 0.1152 - val_loss: 0.0874\n",
      "Epoch 112/600\n",
      "426/426 [==============================] - 0s 279us/sample - loss: 0.1013 - val_loss: 0.1152\n",
      "Epoch 113/600\n",
      "426/426 [==============================] - 0s 1ms/sample - loss: 0.1165 - val_loss: 0.1039\n",
      "Epoch 114/600\n",
      "426/426 [==============================] - 0s 329us/sample - loss: 0.1100 - val_loss: 0.1014\n",
      "Epoch 115/600\n",
      "426/426 [==============================] - 0s 371us/sample - loss: 0.0947 - val_loss: 0.0905\n",
      "Epoch 116/600\n",
      "426/426 [==============================] - 0s 406us/sample - loss: 0.1168 - val_loss: 0.1045\n",
      "Epoch 117/600\n",
      "426/426 [==============================] - 0s 448us/sample - loss: 0.0854 - val_loss: 0.1015\n",
      "Epoch 118/600\n",
      "426/426 [==============================] - 0s 354us/sample - loss: 0.0929 - val_loss: 0.0984\n",
      "Epoch 119/600\n",
      "426/426 [==============================] - 0s 261us/sample - loss: 0.0976 - val_loss: 0.0945\n",
      "Epoch 120/600\n",
      "426/426 [==============================] - 0s 300us/sample - loss: 0.0999 - val_loss: 0.0891\n",
      "Epoch 121/600\n",
      "426/426 [==============================] - 0s 237us/sample - loss: 0.0877 - val_loss: 0.1041\n",
      "Epoch 122/600\n",
      "426/426 [==============================] - 0s 254us/sample - loss: 0.0987 - val_loss: 0.0856\n",
      "Epoch 123/600\n",
      "426/426 [==============================] - 0s 249us/sample - loss: 0.0971 - val_loss: 0.0889\n",
      "Epoch 124/600\n",
      "426/426 [==============================] - 0s 263us/sample - loss: 0.1019 - val_loss: 0.1047\n",
      "Epoch 125/600\n",
      "426/426 [==============================] - 0s 249us/sample - loss: 0.0963 - val_loss: 0.0927\n",
      "Epoch 126/600\n",
      "426/426 [==============================] - 0s 232us/sample - loss: 0.0910 - val_loss: 0.0914\n",
      "Epoch 127/600\n",
      "426/426 [==============================] - 0s 275us/sample - loss: 0.0912 - val_loss: 0.0942\n",
      "Epoch 128/600\n",
      "426/426 [==============================] - 0s 244us/sample - loss: 0.0874 - val_loss: 0.0925\n",
      "Epoch 129/600\n",
      "426/426 [==============================] - 0s 223us/sample - loss: 0.1084 - val_loss: 0.0910\n",
      "Epoch 130/600\n",
      "426/426 [==============================] - 0s 251us/sample - loss: 0.0958 - val_loss: 0.1110\n",
      "Epoch 131/600\n",
      "426/426 [==============================] - 0s 270us/sample - loss: 0.0994 - val_loss: 0.0957\n",
      "Epoch 132/600\n",
      "426/426 [==============================] - 0s 300us/sample - loss: 0.1048 - val_loss: 0.0939\n",
      "Epoch 133/600\n",
      "426/426 [==============================] - 0s 300us/sample - loss: 0.1039 - val_loss: 0.1044\n",
      "Epoch 134/600\n",
      "426/426 [==============================] - 0s 277us/sample - loss: 0.1093 - val_loss: 0.0974\n",
      "Epoch 135/600\n",
      "426/426 [==============================] - 0s 279us/sample - loss: 0.1081 - val_loss: 0.0922\n",
      "Epoch 136/600\n",
      "426/426 [==============================] - 0s 254us/sample - loss: 0.0847 - val_loss: 0.0937\n",
      "Epoch 137/600\n",
      "426/426 [==============================] - 0s 254us/sample - loss: 0.0917 - val_loss: 0.0941\n",
      "Epoch 138/600\n",
      "426/426 [==============================] - 0s 275us/sample - loss: 0.0973 - val_loss: 0.1057\n",
      "Epoch 139/600\n",
      "426/426 [==============================] - 0s 322us/sample - loss: 0.0774 - val_loss: 0.0958\n",
      "Epoch 140/600\n",
      "426/426 [==============================] - 0s 279us/sample - loss: 0.0987 - val_loss: 0.1026\n",
      "Epoch 141/600\n",
      "426/426 [==============================] - 0s 268us/sample - loss: 0.0901 - val_loss: 0.0969\n",
      "Epoch 142/600\n",
      "426/426 [==============================] - 0s 298us/sample - loss: 0.0776 - val_loss: 0.1058\n",
      "Epoch 143/600\n",
      "426/426 [==============================] - 0s 275us/sample - loss: 0.0788 - val_loss: 0.1010\n",
      "Epoch 144/600\n",
      "426/426 [==============================] - 0s 279us/sample - loss: 0.0874 - val_loss: 0.0909\n",
      "Epoch 145/600\n",
      "426/426 [==============================] - 0s 235us/sample - loss: 0.0972 - val_loss: 0.0961\n",
      "Epoch 146/600\n",
      "426/426 [==============================] - 0s 244us/sample - loss: 0.0946 - val_loss: 0.1130\n",
      "Epoch 147/600\n",
      "426/426 [==============================] - 0s 239us/sample - loss: 0.1008 - val_loss: 0.0845\n",
      "Epoch 148/600\n",
      "426/426 [==============================] - 0s 249us/sample - loss: 0.0783 - val_loss: 0.0921\n",
      "Epoch 149/600\n",
      "426/426 [==============================] - 0s 230us/sample - loss: 0.0914 - val_loss: 0.1054\n",
      "Epoch 150/600\n",
      "426/426 [==============================] - 0s 254us/sample - loss: 0.0977 - val_loss: 0.0894\n",
      "Epoch 151/600\n",
      "426/426 [==============================] - 0s 279us/sample - loss: 0.0848 - val_loss: 0.1183\n",
      "Epoch 152/600\n",
      "426/426 [==============================] - 0s 309us/sample - loss: 0.0858 - val_loss: 0.0997\n",
      "Epoch 153/600\n",
      "426/426 [==============================] - 0s 230us/sample - loss: 0.0952 - val_loss: 0.0867\n",
      "Epoch 154/600\n",
      "426/426 [==============================] - 0s 378us/sample - loss: 0.0861 - val_loss: 0.0895\n",
      "Epoch 155/600\n",
      "426/426 [==============================] - 0s 457us/sample - loss: 0.0781 - val_loss: 0.1024\n",
      "Epoch 156/600\n",
      "426/426 [==============================] - 0s 265us/sample - loss: 0.0858 - val_loss: 0.0975\n",
      "Epoch 157/600\n",
      "426/426 [==============================] - 0s 242us/sample - loss: 0.0780 - val_loss: 0.0947\n",
      "Epoch 158/600\n",
      "426/426 [==============================] - 0s 239us/sample - loss: 0.0841 - val_loss: 0.1029\n",
      "Epoch 159/600\n",
      "426/426 [==============================] - 0s 246us/sample - loss: 0.0998 - val_loss: 0.0968\n",
      "Epoch 160/600\n",
      "426/426 [==============================] - 0s 308us/sample - loss: 0.0630 - val_loss: 0.0939\n",
      "Epoch 161/600\n",
      "426/426 [==============================] - 0s 430us/sample - loss: 0.0737 - val_loss: 0.1031\n",
      "Epoch 162/600\n",
      "426/426 [==============================] - 0s 437us/sample - loss: 0.0814 - val_loss: 0.1034\n",
      "Epoch 163/600\n",
      "426/426 [==============================] - 0s 362us/sample - loss: 0.1019 - val_loss: 0.0994\n",
      "Epoch 164/600\n",
      "426/426 [==============================] - 0s 458us/sample - loss: 0.0835 - val_loss: 0.1027\n",
      "Epoch 165/600\n",
      "426/426 [==============================] - 0s 319us/sample - loss: 0.0878 - val_loss: 0.1186\n",
      "Epoch 166/600\n",
      "426/426 [==============================] - 0s 359us/sample - loss: 0.0877 - val_loss: 0.1206\n",
      "Epoch 167/600\n",
      "426/426 [==============================] - 0s 361us/sample - loss: 0.1097 - val_loss: 0.1006\n",
      "Epoch 168/600\n",
      "426/426 [==============================] - 0s 369us/sample - loss: 0.0946 - val_loss: 0.1071\n",
      "Epoch 169/600\n",
      "426/426 [==============================] - 0s 246us/sample - loss: 0.0728 - val_loss: 0.1083\n",
      "Epoch 170/600\n",
      "426/426 [==============================] - 0s 239us/sample - loss: 0.0835 - val_loss: 0.1036\n",
      "Epoch 171/600\n",
      "426/426 [==============================] - 0s 259us/sample - loss: 0.0727 - val_loss: 0.1096\n",
      "Epoch 172/600\n",
      "426/426 [==============================] - 0s 277us/sample - loss: 0.0681 - val_loss: 0.1004\n",
      "Epoch 00172: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f1ec87d308>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          epochs=600,\n",
    "          validation_data=(X_test, y_test),\n",
    "          callbacks=[early_stop]\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is even better performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1f1ecf79848>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_loss = pd.DataFrame(model.history.history)\n",
    "model_loss.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full evaluation of classes\n",
    "\n",
    "We are doing a classification task, we're trying whether a tumor based on its features ir bening or malignant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97        55\n",
      "           1       0.99      0.98      0.98        88\n",
      "\n",
      "    accuracy                           0.98       143\n",
      "   macro avg       0.98      0.98      0.98       143\n",
      "weighted avg       0.98      0.98      0.98       143\n",
      "\n",
      "\n",
      "[[54  1]\n",
      " [ 2 86]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds))\n",
    "print(\"\")\n",
    "print(confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
